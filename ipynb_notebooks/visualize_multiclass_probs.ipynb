{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accb5ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from src.signal_categories import topological_category_labels, topological_category_colors, topological_category_labels_latex\n",
    "from src.signal_categories import filetype_category_labels, filetype_category_colors\n",
    "from src.signal_categories import del1g_simple_category_labels, del1g_simple_category_colors, del1g_detailed_category_labels_latex\n",
    "from src.signal_categories import del1g_detailed_category_labels, del1g_detailed_category_colors, del1g_detailed_category_labels_latex\n",
    "from src.signal_categories import train_category_labels, train_category_colors, train_category_labels_latex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcb1bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.manifold import TSNE, MDS, Isomap\n",
    "from sklearn.decomposition import PCA, FastICA, NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "from src.file_locations import intermediate_files_location\n",
    "\n",
    "print(f\"sklearn version: {sklearn.__version__}\")\n",
    "print(f\"umap version: {umap.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47754f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = \"all_vars\"\n",
    "\n",
    "sig_category_name = \"del1g_simple_signal_category\"\n",
    "#sig_category_name = \"del1g_detailed_signal_category\"\n",
    "\n",
    "if sig_category_name == \"del1g_simple_signal_category\":\n",
    "    sig_categories = train_category_labels\n",
    "    sig_categories_latex = train_category_labels_latex\n",
    "    sig_colors = train_category_colors\n",
    "elif sig_category_name == \"del1g_detailed_signal_category\":\n",
    "    sig_categories = del1g_detailed_category_labels\n",
    "    sig_categories_latex = del1g_detailed_category_labels_latex\n",
    "    sig_colors = del1g_detailed_category_colors\n",
    "elif sig_category_name == \"topological_signal_category\":\n",
    "    sig_categories = topological_category_labels\n",
    "    sig_categories_latex = topological_category_labels_latex\n",
    "    sig_colors = topological_category_colors\n",
    "else:\n",
    "    raise ValueError(f\"Invalid sig_category_name: {sig_category_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98acc60",
   "metadata": {},
   "source": [
    "# File Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004af423",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loading all_df.parquet...\")\n",
    "with open(f\"{intermediate_files_location}/all_df.parquet\", \"rb\") as f:\n",
    "    all_df = pl.read_parquet(f)\n",
    "print(f\"{all_df.height=}, {all_df.width=}\")\n",
    "\n",
    "# this only includes predictions for events passing the preselection used during training\n",
    "print(\"loading predictions.parquet...\")\n",
    "with open(f\"../training_outputs/{training}/predictions.parquet\", \"rb\") as f:\n",
    "    pred_df = pl.read_parquet(f)\n",
    "print(f\"{pred_df.height=}, {pred_df.width=}\")\n",
    "\n",
    "print(\"merging all_df and predictions.pkl...\")\n",
    "merged_df = all_df.join(pred_df, on=[\"filetype\", \"run\", \"subrun\", \"event\"], how=\"left\")\n",
    "\n",
    "merged_df = merged_df.filter(\n",
    "    (pl.col(\"filetype\") != \"data\") & (pl.col(\"filetype\") != \"isotropic_one_gamma_overlay\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fea2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_categories = [\"prob_\" + cat for cat in train_category_labels]\n",
    "\n",
    "# Fill nulls with -1 for the relevant probability columns\n",
    "for prob in prob_categories:\n",
    "    merged_df = merged_df.with_columns(\n",
    "        pl.col(prob).fill_null(-1).alias(prob)\n",
    "    )\n",
    "\n",
    "# Calculate number of train/test events using Polars filtering\n",
    "num_train_events = merged_df.filter(pl.col(\"used_for_training\") == True).height\n",
    "num_test_events = merged_df.filter(pl.col(\"used_for_testing\") == True).height\n",
    "frac_test = num_test_events / (num_train_events + num_test_events)\n",
    "print(f\"weighting up by the fraction of test events: {frac_test:.3f}\")\n",
    "\n",
    "# Modify wc_net_weight as before, using Polars expressions & with_columns\n",
    "merged_df = merged_df.with_columns([\n",
    "    pl.when(pl.col(\"used_for_testing\") == True)\n",
    "      .then(pl.col(\"wc_net_weight\") / frac_test)\n",
    "      .otherwise(pl.col(\"wc_net_weight\"))\n",
    "      .alias(\"wc_net_weight\")\n",
    "])\n",
    "\n",
    "# Only keep rows used for testing\n",
    "merged_df = merged_df.filter(pl.col(\"used_for_testing\") == True)\n",
    "\n",
    "print(f\"{(merged_df.shape)=}\")\n",
    "presel_merged_df = merged_df.filter(pl.col(\"wc_kine_reco_Enu\") > 0)\n",
    "print(f\"{(presel_merged_df.shape)=}\")\n",
    "\n",
    "presel_merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2318bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_frac = 1.5\n",
    "\n",
    "# empty DataFrame using Polars\n",
    "sampled_presel_merged_df = None\n",
    "\n",
    "for sig_category_i, sig_category_label in enumerate(sig_categories):\n",
    "    # Filter using Polars\n",
    "    curr_df = presel_merged_df.filter(pl.col(sig_category_name) == sig_category_i)\n",
    "\n",
    "    curr_sample_frac = sample_frac\n",
    "    if \"1g\" in sig_category_label:\n",
    "        curr_sample_frac = 1e6\n",
    "\n",
    "    # Weighted number of events\n",
    "    num_weighted_events = curr_df.get_column(\"wc_net_weight\").sum()\n",
    "    num_sample_events = int(curr_sample_frac * num_weighted_events)\n",
    "    num_sample_events = min(num_sample_events, curr_df.height)\n",
    "\n",
    "    print(sig_category_label, num_weighted_events, num_sample_events)\n",
    "\n",
    "    # Sample with Polars. Return empty if num_sample_events==0.\n",
    "    if num_sample_events > 0:\n",
    "        if num_sample_events < curr_df.height:\n",
    "            curr_df_sampled = curr_df.sample(n=num_sample_events, with_replacement=False)\n",
    "        else:\n",
    "            curr_df_sampled = curr_df\n",
    "    else:\n",
    "        curr_df_sampled = curr_df.head(0)\n",
    "\n",
    "    if sampled_presel_merged_df is None:\n",
    "        sampled_presel_merged_df = curr_df_sampled\n",
    "    else:\n",
    "        sampled_presel_merged_df = sampled_presel_merged_df.vstack(curr_df_sampled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee0d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_2d_arr = sampled_presel_merged_df[prob_categories].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6808fd87",
   "metadata": {},
   "source": [
    "# Multi-Class Probability Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2162ad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_scaled = probs_2d_arr\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "\n",
    "reducer.fit(probs_scaled)\n",
    "umap_result = reducer.transform(probs_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e1e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "true_sig_categories = sampled_presel_merged_df[sig_category_name].to_numpy()\n",
    "plt.figure(figsize=(12, 7))\n",
    "for i in range(len(sig_categories)):\n",
    "    if \"del1g\" in sig_categories[i] or \"iso1g\" in sig_categories[i]:\n",
    "        continue\n",
    "    true_sig_category_mask = true_sig_categories == i\n",
    "    plt.scatter(umap_result[true_sig_category_mask, 0], umap_result[true_sig_category_mask, 1], alpha=0.2, s=1, c=sig_colors[i])\n",
    "    plt.scatter([], [], s=50, c=sig_colors[i], label=sig_categories_latex[i])\n",
    "plt.title('UMAP Visualization of NGEM Multi-Class BDT Probability Scores')\n",
    "plt.xlabel('UMAP Dimension 1')\n",
    "plt.ylabel('UMAP Dimension 2')\n",
    "min_x, max_x = umap_result[:, 0].min(), umap_result[:, 0].max()\n",
    "min_y, max_y = umap_result[:, 1].min(), umap_result[:, 1].max()\n",
    "x_diff = max_x - min_x\n",
    "y_diff = max_y - min_y\n",
    "plt.xlim(min_x - x_diff * 0.1, max_x + x_diff * 0.4)\n",
    "plt.ylim(min_y - y_diff * 0.1, max_y + y_diff * 0.1)\n",
    "\n",
    "plt.text(0.03, 0.95, 'UMAP projection from 20D Multi-Class\\nBDT score space to 2D, preserving\\ndistances as much as possible\\n\\nIncluding nominal prediction\\nand Del1g signal sample after\\nWC generic $\\geq$ 1 shower preselection', ha='left', va='top', transform=plt.gca().transAxes, fontsize=13)\n",
    "\n",
    "plt.legend(loc=\"upper right\", ncol=1, fontsize=10)\n",
    "plt.savefig(f\"../training_outputs/{training}/score_vis/umap_visualization.png\")\n",
    "plt.savefig(f\"../training_outputs/{training}/score_vis/umap_visualization.pdf\")\n",
    "plt.savefig(f\"../training_outputs/{training}/score_vis/umap_visualization.jpeg\", dpi=400)\n",
    "\n",
    "print_all = False\n",
    "if print_all:\n",
    "    for i in range(len(sig_categories)):\n",
    "        plt.figure(figsize=(3, 2))\n",
    "        true_sig_category_mask = true_sig_categories == sig_categories[i]\n",
    "        plt.scatter(umap_result[true_sig_category_mask, 0], umap_result[true_sig_category_mask, 1], alpha=0.6, s=2, c=sig_colors[i])\n",
    "        plt.scatter([], [], s=50, c=sig_colors[i], label=del1g_detailed_category_labels_latex[i])\n",
    "        plt.title(sig_categories[i])\n",
    "        plt.xlabel('UMAP Dimension 1')\n",
    "        plt.ylabel('UMAP Dimension 2')\n",
    "        min_x, max_x = umap_result[:, 0].min(), umap_result[:, 0].max()\n",
    "        min_y, max_y = umap_result[:, 1].min(), umap_result[:, 1].max()\n",
    "        x_diff = max_x - min_x\n",
    "        y_diff = max_y - min_y\n",
    "        plt.xlim(min_x - x_diff * 0.1, max_x + x_diff * 0.5)\n",
    "        plt.ylim(min_y - y_diff * 0.1, max_y + y_diff * 0.1)\n",
    "        plt.savefig(f\"../training_outputs/{training}/score_vis/{sig_categories[i]}_umap_visualization.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c622d5b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
