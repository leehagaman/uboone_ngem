{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accb5ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from src.signal_categories import topological_category_labels, topological_category_colors, topological_category_labels_latex\n",
    "from src.signal_categories import filetype_category_labels, filetype_category_colors\n",
    "from src.signal_categories import del1g_simple_category_labels, del1g_simple_category_colors, del1g_detailed_category_labels_latex\n",
    "from src.signal_categories import del1g_detailed_category_labels, del1g_detailed_category_colors, del1g_detailed_category_labels_latex\n",
    "from src.signal_categories import train_category_labels, train_category_colors, train_category_labels_latex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcb1bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.manifold import TSNE, MDS, Isomap\n",
    "from sklearn.decomposition import PCA, FastICA, NMF\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "\n",
    "from src.file_locations import intermediate_files_location\n",
    "\n",
    "print(f\"sklearn version: {sklearn.__version__}\")\n",
    "print(f\"umap version: {umap.__version__}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47754f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training = \"first_combined_training\"\n",
    "#training = \"first_wc_training\"\n",
    "#training = \"first_lantern_training\"\n",
    "#training = \"first_mixed_del1g_iso_training\"\n",
    "#training = \"mixed_del1g_iso_training\"\n",
    "training = \"with_numu_generic_pandora_glee\"\n",
    "\n",
    "sig_category_name = \"del1g_simple_signal_category\"\n",
    "#sig_category_name = \"del1g_detailed_signal_category\"\n",
    "\n",
    "if sig_category_name == \"del1g_simple_signal_category\":\n",
    "    sig_categories = train_category_labels\n",
    "    sig_categories_latex = train_category_labels_latex\n",
    "    sig_colors = train_category_colors\n",
    "elif sig_category_name == \"del1g_detailed_signal_category\":\n",
    "    sig_categories = del1g_detailed_category_labels\n",
    "    sig_categories_latex = del1g_detailed_category_labels_latex\n",
    "    sig_colors = del1g_detailed_category_colors\n",
    "elif sig_category_name == \"topological_signal_category\":\n",
    "    sig_categories = topological_category_labels\n",
    "    sig_categories_latex = topological_category_labels_latex\n",
    "    sig_colors = topological_category_colors\n",
    "else:\n",
    "    raise ValueError(f\"Invalid sig_category_name: {sig_category_name}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98acc60",
   "metadata": {},
   "source": [
    "# File Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004af423",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loading all_df.pkl...\")\n",
    "with open(f\"{intermediate_files_location}/all_df.pkl\", \"rb\") as f:\n",
    "    all_df = pickle.load(f)\n",
    "print(f\"{all_df.shape=}\")\n",
    "\n",
    "# this only includes predictions for events passing the preselection used during training\n",
    "print(\"loading predictions.pkl...\")\n",
    "with open(f\"../training_outputs/{training}/predictions.pkl\", \"rb\") as f:\n",
    "    pred_df = pickle.load(f)\n",
    "print(f\"{pred_df.shape=}\")\n",
    "\n",
    "print(\"merging all_df and predictions.pkl...\")\n",
    "merged_df = pd.merge(all_df, pred_df, on=[\"filetype\", \"run\", \"subrun\", \"event\"], how=\"left\")\n",
    "\n",
    "merged_df = merged_df.query(\"filetype != 'data' and filetype != 'isotropic_one_gamma_overlay'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a313b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df[\"filetype\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47fea2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_categories = [\"prob_\" + cat for cat in train_category_labels]\n",
    "\n",
    "for prob in prob_categories:\n",
    "    merged_df[prob] = merged_df[prob].fillna(-1)\n",
    "\n",
    "num_train_events = len(merged_df.query(\"used_for_training == True\"))\n",
    "num_test_events = len(merged_df.query(\"used_for_testing == True\"))\n",
    "frac_test = num_test_events / (num_train_events + num_test_events)\n",
    "print(f\"weighting up by the fraction of test events: {frac_test:.3f}\")\n",
    "\n",
    "modified_net_weights = []\n",
    "used_for_testing = merged_df[\"used_for_testing\"].to_numpy()\n",
    "wc_net_weights = merged_df[\"wc_net_weight\"].to_numpy()\n",
    "for i in range(len(merged_df)):\n",
    "    if used_for_testing[i]:\n",
    "        modified_net_weights.append(wc_net_weights[i] / frac_test)\n",
    "    else:\n",
    "        modified_net_weights.append(wc_net_weights[i])\n",
    "merged_df[\"wc_net_weight\"] = modified_net_weights         \n",
    "\n",
    "merged_df = merged_df.query(\"used_for_testing == True\")\n",
    "\n",
    "print(f\"{merged_df.shape=}\")\n",
    "presel_merged_df = merged_df.query(\"wc_kine_reco_Enu > 0\")\n",
    "print(f\"{presel_merged_df.shape=}\")\n",
    "\n",
    "presel_merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2318bbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sampled_presel_merged_df = presel_merged_df.sample(n=1000)\n",
    "\n",
    "sample_frac = 1.5\n",
    "\n",
    "# empty dataframe\n",
    "sampled_presel_merged_df = pd.DataFrame()\n",
    "for sig_category_i, sig_category_label in enumerate(sig_categories):\n",
    "    curr_df = presel_merged_df.query(f\"{sig_category_name} == {sig_category_i}\")\n",
    "\n",
    "    curr_sample_frac = sample_frac\n",
    "    if \"1g\" in sig_category_label:\n",
    "        curr_sample_frac = 1e6\n",
    "\n",
    "    num_weighted_events = np.sum(curr_df[\"wc_net_weight\"].to_numpy())\n",
    "    num_sample_events = int(curr_sample_frac * num_weighted_events)\n",
    "    num_sample_events = min(num_sample_events, len(curr_df))\n",
    "\n",
    "    print(sig_category_label, num_weighted_events, num_sample_events)\n",
    "\n",
    "    curr_df = curr_df.sample(n=num_sample_events)\n",
    "\n",
    "    sampled_presel_merged_df = pd.concat([sampled_presel_merged_df, curr_df])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee0d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_2d_arr = sampled_presel_merged_df[prob_categories].to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6808fd87",
   "metadata": {},
   "source": [
    "# Multi-Class Probability Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2162ad2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "probs_scaled = probs_2d_arr\n",
    "\n",
    "reducer = umap.UMAP()\n",
    "\n",
    "reducer.fit(probs_scaled)\n",
    "umap_result = reducer.transform(probs_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e1e698",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 14})\n",
    "\n",
    "true_sig_categories = sampled_presel_merged_df[sig_category_name].to_numpy()\n",
    "plt.figure(figsize=(12, 7))\n",
    "for i in range(len(sig_categories)):\n",
    "    if \"del1g\" in sig_categories[i] or \"iso1g\" in sig_categories[i]:\n",
    "        continue\n",
    "    true_sig_category_mask = true_sig_categories == i\n",
    "    plt.scatter(umap_result[true_sig_category_mask, 0], umap_result[true_sig_category_mask, 1], alpha=0.2, s=1, c=sig_colors[i])\n",
    "    plt.scatter([], [], s=50, c=sig_colors[i], label=sig_categories_latex[i])\n",
    "plt.title('UMAP Visualization of NGEM Multi-Class BDT Probability Scores')\n",
    "plt.xlabel('UMAP Dimension 1')\n",
    "plt.ylabel('UMAP Dimension 2')\n",
    "min_x, max_x = umap_result[:, 0].min(), umap_result[:, 0].max()\n",
    "min_y, max_y = umap_result[:, 1].min(), umap_result[:, 1].max()\n",
    "x_diff = max_x - min_x\n",
    "y_diff = max_y - min_y\n",
    "plt.xlim(min_x - x_diff * 0.1, max_x + x_diff * 0.4)\n",
    "plt.ylim(min_y - y_diff * 0.1, max_y + y_diff * 0.1)\n",
    "\n",
    "plt.text(0.03, 0.95, 'UMAP projection from 19D Multi-Class\\nBDT score space to 2D, preserving\\ndistances as much as possible\\n\\nIncluding nominal prediction\\nand Del1g signal sample after\\nWC generic $\\geq$ 1 shower preselection', ha='left', va='top', transform=plt.gca().transAxes, fontsize=13)\n",
    "\n",
    "plt.legend(loc=\"upper right\", ncol=1, fontsize=12)\n",
    "plt.savefig(f\"../training_outputs/{training}/score_vis/umap_visualization.png\")\n",
    "plt.savefig(f\"../training_outputs/{training}/score_vis/umap_visualization.pdf\")\n",
    "plt.savefig(f\"../training_outputs/{training}/score_vis/umap_visualization.jpeg\", dpi=400)\n",
    "\n",
    "print_all = False\n",
    "if print_all:\n",
    "    for i in range(len(sig_categories)):\n",
    "        plt.figure(figsize=(3, 2))\n",
    "        true_sig_category_mask = true_sig_categories == sig_categories[i]\n",
    "        plt.scatter(umap_result[true_sig_category_mask, 0], umap_result[true_sig_category_mask, 1], alpha=0.6, s=2, c=sig_colors[i])\n",
    "        plt.scatter([], [], s=50, c=sig_colors[i], label=del1g_detailed_category_labels_latex[i])\n",
    "        plt.title(sig_categories[i])\n",
    "        plt.xlabel('UMAP Dimension 1')\n",
    "        plt.ylabel('UMAP Dimension 2')\n",
    "        min_x, max_x = umap_result[:, 0].min(), umap_result[:, 0].max()\n",
    "        min_y, max_y = umap_result[:, 1].min(), umap_result[:, 1].max()\n",
    "        x_diff = max_x - min_x\n",
    "        y_diff = max_y - min_y\n",
    "        plt.xlim(min_x - x_diff * 0.1, max_x + x_diff * 0.5)\n",
    "        plt.ylim(min_y - y_diff * 0.1, max_y + y_diff * 0.1)\n",
    "        plt.savefig(f\"../training_outputs/{training}/score_vis/{sig_categories[i]}_umap_visualization.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c622d5b5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
