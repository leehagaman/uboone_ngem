{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79315742",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import psutil\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8894f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_memory_usage_gb():\n",
    "    try:\n",
    "        with open(\"/proc/meminfo\", \"r\") as f:\n",
    "            lines = f.readlines()\n",
    "        meminfo_kb = {}\n",
    "        for line in lines:\n",
    "            parts = line.split(\":\")\n",
    "            if len(parts) < 2:\n",
    "                continue\n",
    "            key = parts[0]\n",
    "            value_tokens = parts[1].strip().split()\n",
    "            if not value_tokens:\n",
    "                continue\n",
    "            # Values are reported in kB\n",
    "            meminfo_kb[key] = int(value_tokens[0])\n",
    "\n",
    "        total_kb = meminfo_kb.get(\"MemTotal\")\n",
    "        avail_kb = meminfo_kb.get(\"MemAvailable\")\n",
    "        if total_kb is None or avail_kb is None:\n",
    "            return None\n",
    "        used_kb = total_kb - avail_kb\n",
    "        used_gb = used_kb / (1024 * 1024)\n",
    "        total_gb = total_kb / (1024 * 1024)\n",
    "        percent = (used_kb / total_kb) * 100.0\n",
    "        return used_gb, total_gb, percent\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def print_system_memory_usage_gb():\n",
    "    used_gb, total_gb, percent = get_system_memory_usage_gb()\n",
    "    if used_gb is not None:\n",
    "        print(f\"[mem] {used_gb:5.2f}/{total_gb:5.2f} GB ({percent:5.1f}%)\", flush=True)\n",
    "\n",
    "print_system_memory_usage_gb()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e598b418",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_dfs = []\n",
    "\n",
    "print_system_memory_usage_gb()\n",
    "\n",
    "for file in os.listdir(\"/nevis/riverside/data/leehagaman/ngem/intermediate_files/\"):\n",
    "    if file.endswith(\".parquet\"):\n",
    "        print(f\"Reading {file}\")\n",
    "        curr_pl_df = pl.read_parquet(f\"/nevis/riverside/data/leehagaman/ngem/intermediate_files/{file}\")\n",
    "        curr_pl_df = curr_pl_df.with_columns([pl.col(pl.Float64).cast(pl.Float32)])\n",
    "        curr_pl_df = curr_pl_df.with_columns([pl.col(pl.Int32).cast(pl.Int64)])\n",
    "        pl_dfs.append(curr_pl_df)\n",
    "        print(f\"Read {file}, estimated size: {pl_dfs[-1].estimated_size() / 1e9:.2f} GB\")\n",
    "        print_system_memory_usage_gb()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2680d446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_columns_for_concat(dfs):\n",
    "    # Find all columns across all DataFrames\n",
    "    all_cols = {col for df in dfs for col in df.columns}\n",
    "\n",
    "    # Build a mapping of column -> dtype (prefer from first df that has it)\n",
    "    dtype_map = {}\n",
    "    for df in dfs:\n",
    "        for col, dtype in zip(df.columns, df.dtypes):\n",
    "            dtype_map.setdefault(col, dtype)\n",
    "\n",
    "    aligned = []\n",
    "    for df in dfs:\n",
    "        missing = all_cols - set(df.columns)\n",
    "        if missing:\n",
    "            # Add missing columns as nulls, cast to the desired dtype\n",
    "            defaults = [\n",
    "                pl.lit(None).cast(dtype_map[c]).alias(c)\n",
    "                for c in missing\n",
    "            ]\n",
    "            df = df.with_columns(defaults)\n",
    "        # Ensure consistent column order\n",
    "        df = df.select(sorted(all_cols))\n",
    "        aligned.append(df)\n",
    "\n",
    "    return aligned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6c13d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned = align_columns_for_concat(pl_dfs)\n",
    "print_system_memory_usage_gb()\n",
    "total_concat_pl_df = pl.concat(aligned, how=\"vertical\")\n",
    "print(f\"Total concatenated Polars DataFrame size: {total_concat_pl_df.estimated_size() / 1e9:.2f} GB\")\n",
    "\n",
    "total_concat_pl_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b009ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to pandas\n",
    "total_concat_pd_df = total_concat_pl_df.to_pandas()\n",
    "print_system_memory_usage_gb()\n",
    "\n",
    "# convert to pickle\n",
    "total_concat_pd_df.to_pickle(\"/nevis/riverside/data/leehagaman/ngem/intermediate_files/total_concat_pd_df.pkl\")\n",
    "print_system_memory_usage_gb()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6a9ebc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd56dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1/0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97cc962",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a sample dataset\n",
    "N = 10_000_000\n",
    "data1 = {\n",
    "    \"ints\": np.random.randint(0, 1000, N),\n",
    "    \"floats\": np.random.randn(N),\n",
    "    \"strings\": np.random.choice([\"apple\", \"banana\", \"cherry\"], N),\n",
    "}\n",
    "\n",
    "data2 = {\n",
    "    \"ints\": np.random.randint(0, 1000, N),\n",
    "    \"floats\": np.random.randn(N),\n",
    "    \"strings\": np.random.choice([\"apple\", \"banana\", \"cherry\"], N),\n",
    "}\n",
    "\n",
    "# Measure pandas memory usage\n",
    "df1_pd = pd.DataFrame(data1)\n",
    "df2_pd = pd.DataFrame(data2)\n",
    "pandas_mem_1 = df1_pd.memory_usage(deep=True).sum() / 1e6\n",
    "print(f\"Pandas memory df1: {pandas_mem_1:.2f} MB\")\n",
    "pandas_mem_2 = df2_pd.memory_usage(deep=True).sum() / 1e6\n",
    "print(f\"Pandas memory df2: {pandas_mem_2:.2f} MB\")\n",
    "df_pd = pd.concat([df1_pd, df2_pd])\n",
    "pandas_mem_concat = df_pd.memory_usage(deep=True).sum() / 1e6\n",
    "print(f\"Pandas memory concatenated: {pandas_mem_concat:.2f} MB\")\n",
    "\n",
    "# Convert to Polars\n",
    "df1_pl = pl.from_pandas(df1_pd)\n",
    "df2_pl = pl.from_pandas(df2_pd)\n",
    "polars_mem_1 = df1_pl.estimated_size() / 1e6\n",
    "print(f\"Polars memory df1: {polars_mem_1:.2f} MB\")\n",
    "polars_mem_2 = df2_pl.estimated_size() / 1e6\n",
    "print(f\"Polars memory df2: {polars_mem_2:.2f} MB\")\n",
    "df_pl = pl.concat([df1_pl, df2_pl], how=\"vertical\")\n",
    "polars_mem_concat = df_pl.estimated_size() / 1e6\n",
    "print(f\"Polars memory concatenated: {polars_mem_concat:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17b2a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load /nevis/riverside/data/leehagaman/ngem/intermediate_files/intermediate_files/all_df.pkl into pandas\n",
    "df1_pd = pd.read_pickle(\"/nevis/riverside/data/leehagaman/ngem/intermediate_files/all_df.pkl\")\n",
    "df2_pd = pd.read_pickle(\"/nevis/riverside/data/leehagaman/ngem/intermediate_files/all_df.pkl\")\n",
    "\n",
    "pandas_mem_1 = df1_pd.memory_usage(deep=True).sum() / 1e6\n",
    "print(f\"Pandas memory df1: {pandas_mem_1:.2f} MB\")\n",
    "pandas_mem_2 = df2_pd.memory_usage(deep=True).sum() / 1e6\n",
    "print(f\"Pandas memory df2: {pandas_mem_2:.2f} MB\")\n",
    "df_pd = pd.concat([df1_pd, df2_pd])\n",
    "pandas_mem_concat = \n",
    "print(f\"Pandas memory concatenated: {df_pd.memory_usage(deep=True).sum() / 1e9:.2f} GB\")\n",
    "\n",
    "df1_pl = pl.from_pandas(df1_pd)\n",
    "df2_pl = pl.from_pandas(df2_pd)\n",
    "\n",
    "del df1_pd, df2_pd\n",
    "\n",
    "polars_mem_1 = df1_pl.estimated_size() / 1e6\n",
    "print(f\"Polars memory df1: {polars_mem_1:.2f} MB\")\n",
    "polars_mem_2 = df2_pl.estimated_size() / 1e6\n",
    "print(f\"Polars memory df2: {polars_mem_2:.2f} MB\")\n",
    "\n",
    "#df_pl = pl.concat([df1_pl, df2_pl], how=\"vertical\")\n",
    "#polars_mem_concat = df_pl.estimated_size() / 1e6\n",
    "#print(f\"Polars memory concatenated: {polars_mem_concat:.2f} MB\")\n",
    "\n",
    "df1_pl.write_parquet(\"df1_pl.parquet\")\n",
    "df2_pl.write_parquet(\"df2_pl.parquet\")\n",
    "\n",
    "del df1_pl, df2_pl\n",
    "\n",
    "df_pl = pl.read_parquet([\"df1_pl.parquet\", \"df2_pl.parquet\"])\n",
    "polars_mem = df_pl.estimated_size() / 1e6\n",
    "print(f\"Polars memory: {polars_mem:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de99d07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(\"/nevis/riverside/data/leehagaman/ngem/intermediate_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525f4559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# open curr_df_pl_0.parquet with polars\n",
    "df_pl = pl.read_parquet(\"/nevis/riverside/data/leehagaman/ngem/intermediate_files/curr_df_pl_0.parquet\")\n",
    "\n",
    "# change to pandas\n",
    "df = df_pl.to_pandas()\n",
    "df[[\"filetype\", \"filename\", \"run\", \"subrun\", \"event\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797532fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9473e87b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
