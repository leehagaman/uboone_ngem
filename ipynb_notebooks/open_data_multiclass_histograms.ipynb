{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accb5ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "mpl.rcParams['hatch.linewidth'] = 0.2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from tqdm.notebook import tqdm\n",
    "import polars as pl\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from src.signal_categories import topological_category_labels, topological_category_colors, topological_category_labels_latex, topological_category_hatches, topological_categories_dic\n",
    "from src.signal_categories import filetype_category_labels, filetype_category_colors, filetype_category_hatches\n",
    "from src.signal_categories import del1g_detailed_category_labels, del1g_detailed_category_colors, del1g_detailed_category_labels_latex, del1g_detailed_category_hatches, del1g_detailed_categories_dic\n",
    "from src.signal_categories import del1g_simple_category_labels, del1g_simple_category_colors, del1g_simple_category_labels_latex, del1g_simple_category_hatches, del1g_simple_categories_dic\n",
    "from src.signal_categories import train_category_labels, train_category_labels_latex\n",
    "\n",
    "from src.ntuple_variables.pandora_variables import pandora_scalar_second_half_training_vars\n",
    "\n",
    "from src.file_locations import intermediate_files_location\n",
    "\n",
    "from src.plot_helpers import make_plot\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98acc60",
   "metadata": {},
   "source": [
    "# File Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443fc157",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = \"all_vars\"\n",
    "#training = \"all_vars_small\"\n",
    "\n",
    "reco_categories = train_category_labels\n",
    "reco_category_labels_latex = train_category_labels_latex\n",
    "\n",
    "if \"nue_only\" in training:\n",
    "    reco_categories = [\"not_nue\", \"nue\"]\n",
    "    reco_category_labels_latex = [\"not_nue\", \"nue\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004af423",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loading all_df.parquet...\")\n",
    "all_df = pl.read_parquet(f\"{intermediate_files_location}/all_df.parquet\")\n",
    "print(f\"{all_df.shape=}\")\n",
    "\n",
    "# this only includes predictions for events passing the preselection used during training\n",
    "print(\"loading predictions.parquet...\")\n",
    "pred_df = pl.read_parquet(f\"../training_outputs/{training}/predictions.parquet\")\n",
    "print(f\"{pred_df.shape=}\")\n",
    "\n",
    "print(\"merging all_df and predictions.pkl...\")\n",
    "merged_df_no_data_drop = all_df.join(\n",
    "    pred_df, \n",
    "    on=[\"filetype\", \"run\", \"subrun\", \"event\"], \n",
    "    how=\"left\"\n",
    ")\n",
    "del all_df\n",
    "del pred_df\n",
    "\n",
    "# Use polars expressions to set \"used_for_training\" and \"used_for_testing\" for wc_kine_reco_Enu < 0\n",
    "merged_df_no_data_drop = merged_df_no_data_drop.with_columns([\n",
    "    pl.when(pl.col(\"wc_kine_reco_Enu\") < 0)\n",
    "      .then(False)\n",
    "      .otherwise(pl.col(\"used_for_training\"))\n",
    "      .alias(\"used_for_training\"),\n",
    "    pl.when(pl.col(\"wc_kine_reco_Enu\") < 0)\n",
    "      .then(True)\n",
    "      .otherwise(pl.col(\"used_for_testing\"))\n",
    "      .alias(\"used_for_testing\")\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7565270e",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pred = merged_df_no_data_drop.filter(\n",
    "    ~pl.col(\"filetype\").is_in([\"data\", \"isotropic_one_gamma_overlay\", \"delete_one_gamma_overlay\"])\n",
    ")\n",
    "full_data = merged_df_no_data_drop.filter(pl.col(\"filetype\") == \"data\")\n",
    "\n",
    "prob_categories = [\"prob_\" + cat for cat in reco_categories]\n",
    "for prob in prob_categories:\n",
    "    full_pred = full_pred.with_columns(pl.col(prob).fill_null(-1))\n",
    "    full_data = full_data.with_columns(pl.col(prob).fill_null(-1))\n",
    "\n",
    "generic_pred_df = full_pred.filter(pl.col(\"wc_kine_reco_Enu\") > 0)\n",
    "non_generic_pred_df = full_pred.filter(pl.col(\"wc_kine_reco_Enu\") < 0)\n",
    "del full_pred\n",
    "\n",
    "num_train_events = generic_pred_df.filter(pl.col(\"used_for_training\") == True).height\n",
    "num_test_events = generic_pred_df.filter(pl.col(\"used_for_testing\") == True).height\n",
    "print(f\"num_train_events: {num_train_events}, num_test_events: {num_test_events}\")\n",
    "frac_test = num_test_events / (num_train_events + num_test_events)\n",
    "print(f\"weighting up preselected prediction events by the fraction of test/train events: {frac_test:.3f}\")\n",
    "\n",
    "# Modify weights using polars expressions\n",
    "generic_pred_df = generic_pred_df.with_columns(\n",
    "    pl.when(pl.col(\"used_for_testing\"))\n",
    "    .then(pl.col(\"wc_net_weight\") / frac_test)\n",
    "    .otherwise(pl.col(\"wc_net_weight\"))\n",
    "    .alias(\"wc_net_weight\")\n",
    ")\n",
    "\n",
    "full_pred = pl.concat([generic_pred_df, non_generic_pred_df])\n",
    "del generic_pred_df\n",
    "del non_generic_pred_df\n",
    "\n",
    "test_pred = full_pred.filter(pl.col(\"used_for_testing\") == True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bbe9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pl.concat([test_pred, full_data])\n",
    "del test_pred\n",
    "del full_data\n",
    "presel_merged_df = merged_df.filter(pl.col(\"wc_kine_reco_Enu\") > 0)\n",
    "\n",
    "presel_merged_data_df = presel_merged_df.filter(pl.col(\"filetype\") == \"data\")\n",
    "presel_merged_pred_df = presel_merged_df.filter(pl.col(\"filetype\") != \"data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63397151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create boolean expressions for each condition\n",
    "shw_sp_n_20mev_showers_expr = pl.col(\"wc_shw_sp_n_20mev_showers\") > 0\n",
    "reco_nuvtxX_expr = (pl.col(\"wc_reco_nuvtxX\") > 5.0) & (pl.col(\"wc_reco_nuvtxX\") < 250.0)\n",
    "single_photon_numu_score_expr = pl.col(\"wc_single_photon_numu_score\") > 0.4\n",
    "single_photon_other_score_expr = pl.col(\"wc_single_photon_other_score\") > 0.2\n",
    "single_photon_ncpi0_score_expr = pl.col(\"wc_single_photon_ncpi0_score\") > -0.05\n",
    "single_photon_nue_score_expr = pl.col(\"wc_single_photon_nue_score\") > -1.0\n",
    "shw_sp_n_20br1_showers_expr = pl.col(\"wc_shw_sp_n_20br1_showers\") == 1\n",
    "\n",
    "# Combine all conditions\n",
    "selection_expr = (\n",
    "    shw_sp_n_20mev_showers_expr &\n",
    "    reco_nuvtxX_expr &\n",
    "    single_photon_numu_score_expr &\n",
    "    single_photon_other_score_expr &\n",
    "    single_photon_ncpi0_score_expr &\n",
    "    single_photon_nue_score_expr &\n",
    "    shw_sp_n_20br1_showers_expr\n",
    ")\n",
    "\n",
    "# Add selection column using when/then/otherwise\n",
    "presel_merged_df = presel_merged_df.with_columns(\n",
    "    pl.when(selection_expr)\n",
    "    .then(1)\n",
    "    .otherwise(0)\n",
    "    .alias(\"erin_inclusive_1g_sel\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee0d9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the probabilities and find argmax index for each row\n",
    "presel_merged_df = presel_merged_df.with_columns(\n",
    "    pl.concat_list(prob_categories).list.arg_max().alias(\"reco_category_argmax_index\")\n",
    ")\n",
    "\n",
    "# Build list of query strings\n",
    "reco_category_argmax_queries = []\n",
    "for i, signal_category in enumerate(reco_categories):\n",
    "    reco_category_argmax_queries.append(pl.col(\"reco_category_argmax_index\") == i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c090b98",
   "metadata": {},
   "source": [
    "# Preselection Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f353ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_plot(pred_and_data_sel_df=presel_merged_df, bins=np.linspace(0, 2000, 21), var=\"wc_kine_reco_Enu\", display_var=r\"WC Reconstructed $E_\\nu$ (MeV)\", title=\"Preselection\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e746e4c",
   "metadata": {},
   "source": [
    "# BDT Score Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "901795d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for category in [\"1gNp\", \"1g0p\", \"1gNp1mu\", \"1g0p1mu\", \"nueCC_Np\", \"nueCC_0p\"]:\n",
    "#    make_plot(presel_merged_df, bins=np.linspace(0, 1, 21), var=f\"prob_{category}\", title=\"Preselection\", log_y=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d490bac2",
   "metadata": {},
   "source": [
    "# BDT Variable Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2ca26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_sel_df = presel_merged_df.filter(pl.col(\"filetype\") != \"data\")\n",
    "#data_sel_df = presel_merged_df.filter(pl.col(\"filetype\") == \"data\")\n",
    "#for var in pandora_scalar_second_half_training_vars:\n",
    "#    make_plot(pred_sel_df=pred_sel_df, data_sel_df=data_sel_df, var=var, title=\"Preselection\", breakdown_type=\"filetype\", log_y=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f0575ba",
   "metadata": {},
   "source": [
    "# Topology Grid Histograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df12d1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_cut_values = [\n",
    "    pl.col(\"prob_1gNp\") > 0.3,\n",
    "    pl.col(\"prob_1g0p\") > 0.9,\n",
    "    pl.col(\"prob_1gNp1mu\") > 0.5, \n",
    "    pl.col(\"prob_1g0p1mu\") > 0.2,\n",
    "    pl.col(\"prob_1g_outFV\") > 0.5,\n",
    "    None, #pl.col(\"prob_NC1pi0_Np\") > 0.5,\n",
    "    None, #pl.col(\"prob_NC1pi0_0p\") > 0.5,\n",
    "    (pl.col(\"prob_numuCC1pi0_Np\") > 0.3) & (pl.col(\"prob_numuCC1pi0_0p\") < 0.1),\n",
    "    pl.col(\"prob_numuCC1pi0_0p\") > 0.1,\n",
    "    pl.col(\"prob_1pi0_outFV\") > 0.1,\n",
    "    (pl.col(\"prob_nueCC_Np\") > 0.05) & (pl.col(\"prob_nueCC_0p\") < 0.05),\n",
    "    pl.col(\"prob_nueCC_0p\") > 0.05,\n",
    "    pl.col(\"prob_numuCC_Np\") > 0.5,\n",
    "    pl.col(\"prob_numuCC_0p\") > 0.5,\n",
    "    pl.col(\"prob_multi_pi0\") > 0.02,\n",
    "    pl.col(\"prob_eta_other\") > 0.01,\n",
    "    None, #pl.col(\"prob_NC_no_gamma\") > 0.5,\n",
    "    None, #pl.col(\"prob_other_outFV_dirt\") > 0.5,\n",
    "    None, #pl.col(\"prob_ext\") > 0.5,\n",
    "]\n",
    "\n",
    "reco_category_queries_possible_overlap = []\n",
    "for i, custom_cut_value in enumerate(custom_cut_values):\n",
    "    if custom_cut_value is None:\n",
    "        reco_category_queries_possible_overlap.append(reco_category_argmax_queries[i])\n",
    "    else:\n",
    "        reco_category_queries_possible_overlap.append(custom_cut_value)\n",
    "\n",
    "reco_category_queries = []\n",
    "for i in range(len(reco_category_queries_possible_overlap)):\n",
    "    curr_query = reco_category_queries_possible_overlap[i]\n",
    "    for j in range(i):\n",
    "        curr_query = curr_query & ~reco_category_queries_possible_overlap[j]\n",
    "\n",
    "    reco_category_queries.append(curr_query)\n",
    "\n",
    "# saving this to a file so we can apply the same cuts in the efficiency plots\n",
    "with open(f\"{intermediate_files_location}/reco_category_queries.pkl\", \"wb\") as f:\n",
    "    pickle.dump(reco_category_queries, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f469585",
   "metadata": {},
   "outputs": [],
   "source": [
    "do_grid = True\n",
    "\n",
    "iso1g_norm_factor = None\n",
    "del1g_norm_factor = None\n",
    "\n",
    "do_full_pred_grid = False\n",
    "include_data = True\n",
    "\n",
    "if do_grid:\n",
    "\n",
    "    additional_scaling_factor = 1\n",
    "\n",
    "    breakdown_queries = []\n",
    "    for i in range(len(del1g_detailed_category_labels)):\n",
    "        breakdown_queries.append(pl.col('del1g_detailed_signal_category') == i)\n",
    "    breakdown_labels = del1g_detailed_category_labels\n",
    "    breakdown_labels_latex = del1g_detailed_category_labels_latex\n",
    "    breakdown_colors = del1g_detailed_category_colors\n",
    "    breakdown_hatches = del1g_detailed_category_hatches\n",
    "\n",
    "    if do_full_pred_grid:\n",
    "        additional_scaling_factor = 1.11e21 / 3.33e19\n",
    "        \"\"\"breakdown_queries = []\n",
    "        for i in range(len(del1g_simple_category_labels)):\n",
    "            breakdown_queries.append(pl.col('del1g_simple_signal_category') == i)\n",
    "        breakdown_labels = del1g_simple_category_labels\n",
    "        breakdown_labels_latex = del1g_simple_category_labels_latex\n",
    "        breakdown_colors = del1g_simple_category_colors\n",
    "        breakdown_hatches = del1g_simple_category_hatches\"\"\"\n",
    "\n",
    "    fig, axs = plt.subplots(7, 5, figsize=(20, 20))\n",
    "    axs = axs.flatten()\n",
    "\n",
    "    bins = np.linspace(0, 2000, 21)\n",
    "    bin_centers = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "    for i in tqdm(range(len(reco_categories))):\n",
    "\n",
    "        signal_category = reco_categories[i]\n",
    "        signal_category_latex = reco_category_labels_latex[i]\n",
    "\n",
    "        sel_df = presel_merged_df.filter(reco_category_queries[i])\n",
    "\n",
    "        pred_sel_df = sel_df.filter(pl.col(\"filetype\") != \"data\")\n",
    "        data_sel_df = sel_df.filter(pl.col(\"filetype\") == \"data\")\n",
    "\n",
    "        breakdown_counts = []\n",
    "        for breakdown_i, breakdown_label in enumerate(breakdown_labels):\n",
    "            curr_df = pred_sel_df.filter(breakdown_queries[breakdown_i])\n",
    "            breakdown_counts.append(np.histogram(curr_df.select(\"wc_kine_reco_Enu\").to_numpy(), \n",
    "                                              weights=curr_df.select(\"wc_net_weight\").to_numpy()*additional_scaling_factor, \n",
    "                                              bins=bins)[0])\n",
    "        data_counts = np.histogram(data_sel_df.select(\"wc_kine_reco_Enu\").to_numpy().flatten(), bins=bins)[0]\n",
    "\n",
    "        axnum = i\n",
    "        if i >= 14: # other background categories, start new row\n",
    "            axnum = i + 1\n",
    "\n",
    "        bottom = np.zeros(len(bins)-1)\n",
    "        for breakdown_i, (breakdown_label, breakdown_count, breakdown_color, breakdown_hatch, breakdown_label_latex) in enumerate(zip(breakdown_labels, breakdown_counts, breakdown_colors, breakdown_hatches, breakdown_labels_latex)):\n",
    "            if \"iso1g\" in breakdown_label:\n",
    "                if iso1g_norm_factor == None:\n",
    "                    continue\n",
    "                breakdown_count = breakdown_count * iso1g_norm_factor\n",
    "            elif \"del1g\" in breakdown_label:\n",
    "                if del1g_norm_factor == None:\n",
    "                    continue\n",
    "                breakdown_count = breakdown_count * del1g_norm_factor\n",
    "            elif \"data\" in breakdown_label:\n",
    "                continue\n",
    "\n",
    "            n, _, _ = axs[axnum].hist(bin_centers, weights=breakdown_count, bins=bins, bottom=bottom if breakdown_i > 0 else None, color=breakdown_color, hatch=breakdown_hatch, label=breakdown_label_latex)\n",
    "            axs[axnum].hist(bin_centers, weights=breakdown_count, bins=bins, bottom=bottom if breakdown_i > 0 else None, histtype=\"step\", color=\"k\", lw=0.5)\n",
    "\n",
    "            if breakdown_i == 0:\n",
    "                bottom = n\n",
    "            else:\n",
    "                bottom += n\n",
    "\n",
    "        #print(signal_category, np.sum(breakdown_counts))\n",
    "\n",
    "        if include_data:\n",
    "            axs[axnum].errorbar(bin_centers, data_counts, yerr=np.sqrt(data_counts), fmt=\"o\", color=\"k\", lw=0.5, capsize=2, capthick=1, markersize=2, label=\"3.33e19 POT Run 4b Data\")\n",
    "\n",
    "        max_pred = np.max(bottom)\n",
    "        max_data = np.max(data_counts)\n",
    "\n",
    "        axs[axnum].set_ylim(0, max(max_pred, max_data) * 1.1)\n",
    "\n",
    "        if axnum == 19:\n",
    "            axs[axnum].legend(ncol=4, loc='upper right', bbox_to_anchor=(-1, -0.5))\n",
    "\n",
    "        if axnum in [15, 16, 17, 18, 19]:\n",
    "            axs[axnum].set_xlabel(r\"WC Reconstructed $E_\\nu$ (MeV)\")\n",
    "        if axnum % 5 == 0: # Only show y-label for leftmost column\n",
    "            if additional_scaling_factor != 1.0:\n",
    "                axs[axnum].set_ylabel(f\"Counts (weighted\\nto {additional_scaling_factor*3.33e19:.2e} POT)\")\n",
    "            else:\n",
    "                axs[axnum].set_ylabel(\"Counts (weighted\\nto 3.33e19 POT)\")\n",
    "        axs[axnum].set_title(f\"{signal_category_latex} Selection\")\n",
    "        axs[axnum].set_xlim(0, 2000)\n",
    "\n",
    "    for axnum in range(len(axs)):\n",
    "        if axnum in [14] or axnum > 19:\n",
    "            axs[axnum].remove()\n",
    "\n",
    "    fig.subplots_adjust(hspace=0.5, wspace=0.3, bottom=0.15)\n",
    "\n",
    "    plt.savefig(f\"../plots/multiclass_histograms_{training}.pdf\")\n",
    "    plt.savefig(f\"../plots/multiclass_histograms_{training}.png\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7101a601",
   "metadata": {},
   "source": [
    "# One Shower Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481e5cc7",
   "metadata": {},
   "source": [
    "## Multi-class BDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bd6a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "for reco_category in [\"1gNp\", \"1g0p\", \"1gNp1mu\", \"1g0p1mu\", \"nueCC_Np\", \"nueCC_0p\"]:\n",
    "    reco_category_i = reco_categories.index(reco_category)\n",
    "    reco_category_latex = reco_category_labels_latex[reco_category_i]\n",
    "\n",
    "    sel_df = presel_merged_df.filter(reco_category_queries[reco_category_i])\n",
    "\n",
    "    make_plot(pred_and_data_sel_df=sel_df, bins=np.linspace(0, 3000, 31), var=\"wc_kine_reco_Enu\", display_var=r\"WC Reconstructed $E_\\nu$ (MeV)\", title=reco_category_latex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62939fa6",
   "metadata": {},
   "source": [
    "## Older 1g selections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1cea4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for reco_category in [\"NCDeltaRad_1gNp\", \"NCDeltaRad_1g0p\", \"erin_inclusive_1g\", \"WC_nueCC_Np\", \"WC_nueCC_0p\"]:\n",
    "    \n",
    "    if reco_category == \"presel\":\n",
    "        sel_df = presel_merged_df\n",
    "        reco_category_latex = \"Preselection\"\n",
    "    elif reco_category == \"NCDeltaRad_1gNp\":\n",
    "        sel_df = presel_merged_df.filter(\n",
    "            (pl.col(\"wc_kine_reco_Enu\") > 0) & \n",
    "            (pl.col(\"wc_nc_delta_score\") > 2.61) & \n",
    "            (pl.col(\"wc_reco_num_protons_35_MeV\") > 0)\n",
    "        )\n",
    "        reco_category_latex = r\"NC $\\Delta\\rightarrow N\\gamma$ $Np$\"\n",
    "    elif reco_category == \"NCDeltaRad_1g0p\":\n",
    "        sel_df = presel_merged_df.filter(\n",
    "            (pl.col(\"wc_kine_reco_Enu\") > 0) & \n",
    "            (pl.col(\"wc_nc_delta_score\") > 2.61) & \n",
    "            (pl.col(\"wc_reco_num_protons_35_MeV\") == 0)\n",
    "        )\n",
    "        reco_category_latex = r\"NC $\\Delta\\rightarrow N\\gamma$ $0p$\"\n",
    "    elif reco_category == \"erin_inclusive_1g\":\n",
    "        sel_df = presel_merged_df.filter(pl.col(\"erin_inclusive_1g_sel\") == 1)\n",
    "        reco_category_latex = r\"Erin Inclusive $1g$\"\n",
    "    elif reco_category == \"WC_nueCC_Np\":\n",
    "        sel_df = presel_merged_df.filter(\n",
    "            (pl.col(\"wc_nue_score\") > 7) & \n",
    "            (pl.col(\"wc_kine_reco_Enu\") > 0) & \n",
    "            (pl.col(\"wc_reco_num_protons_35_MeV\") > 0)\n",
    "        )\n",
    "        reco_category_latex = r\"WC $\\nu_e$CC $Np$\"\n",
    "    elif reco_category == \"WC_nueCC_0p\":\n",
    "        sel_df = presel_merged_df.filter(\n",
    "            (pl.col(\"wc_nue_score\") > 7) & \n",
    "            (pl.col(\"wc_kine_reco_Enu\") > 0) & \n",
    "            (pl.col(\"wc_reco_num_protons_35_MeV\") == 0)\n",
    "        )\n",
    "        reco_category_latex = r\"WC $\\nu_e$CC $0p$\"\n",
    "    \n",
    "    make_plot(pred_and_data_sel_df=sel_df, bins=np.linspace(0, 3000, 31), var=\"wc_kine_reco_Enu\", display_var=r\"WC Reconstructed $E_\\nu$ (MeV)\", title=reco_category_latex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c68379e",
   "metadata": {},
   "source": [
    "# Post-Selection Studies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34655f2",
   "metadata": {},
   "source": [
    "## Backward Projected Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d09da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "for reco_category in [\"preselection\", \"1g0p\", \"other_outFV_dirt\"]:\n",
    "\n",
    "    if reco_category == \"preselection\":\n",
    "        sel_df = presel_merged_df\n",
    "        reco_category_latex = \"Preselection\"\n",
    "    elif reco_category in reco_categories:\n",
    "        reco_category_i = reco_categories.index(reco_category)\n",
    "        sel_df = presel_merged_df.filter(reco_category_queries[reco_category_i])\n",
    "        reco_category_latex = reco_category_labels_latex[reco_category_i]\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid selection type: {reco_category}\")\n",
    "\n",
    "    for var, bins in [\n",
    "            (\"wc_reco_backwards_projected_dist\", np.linspace(-100, 2000, 43)),\n",
    "            (\"wc_reco_distance_to_boundary\", np.linspace(0, 150, 31)), \n",
    "            (\"wc_reco_shower_theta\", np.linspace(0, 180, 19)),\n",
    "            (\"wc_reco_shower_phi\", np.linspace(-180, 180, 19)),\n",
    "        ]:\n",
    "\n",
    "        make_plot(pred_and_data_sel_df=sel_df, bins=bins, var=var, display_var=var, title=reco_category_latex)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb8b323",
   "metadata": {},
   "source": [
    "## Di-photon Invariant Mass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70eaa0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for reco_category in [\"NC1pi0_Np\", \"NC1pi0_0p\", \"eta_other\"]:\n",
    "    if reco_category in reco_categories:\n",
    "        reco_category_i = reco_categories.index(reco_category)\n",
    "        sel_df = presel_merged_df.filter(reco_category_queries[reco_category_i])\n",
    "        pred_sel_df = sel_df.filter(pl.col(\"filetype\") != \"data\")\n",
    "        data_sel_df = sel_df.filter(pl.col(\"filetype\") == \"data\")\n",
    "        reco_category_latex = reco_category_labels_latex[reco_category_i]\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid selection type: {reco_category}\")\n",
    "\n",
    "    for var, bins in [\n",
    "            (\"wc_kine_pio_mass\", np.linspace(0, 1000, 41)),\n",
    "            (\"lantern_diphoton_mass\", np.linspace(0, 1000, 41)), \n",
    "            #(\"wc_kine_pio_angle\", np.linspace(0, 180, 19)),\n",
    "            #(\"lantern_diphoton_opening_angle\", np.linspace(0, 180, 19)),\n",
    "            #(\"wc_kine_pio_energy_1\", np.linspace(0, 1000, 21)),\n",
    "            #(\"lantern_diphoton_energy\", np.linspace(0, 100000, 21)),\n",
    "        ]:\n",
    "\n",
    "        make_plot(pred_sel_df=pred_sel_df, data_sel_df=data_sel_df, bins=bins, var=var, display_var=var, title=reco_category_latex)\n",
    "\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.hist2d(pred_sel_df.select(\"lantern_diphoton_mass\").to_numpy().flatten(), pred_sel_df.select(\"wc_kine_pio_mass\").to_numpy().flatten(), \n",
    "                    weights=pred_sel_df.select(\"wc_net_weight\").to_numpy().flatten(), \n",
    "                    bins=np.linspace(0, 1000, 41))\n",
    "    plt.colorbar()\n",
    "    plt.xlabel(\"Lantern Diphoton Mass (MeV)\")\n",
    "    plt.ylabel(\"WC Diphoton Mass (MeV)\")\n",
    "    plt.title(reco_category_latex + \" Prediction\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30df8df",
   "metadata": {},
   "source": [
    "## Blips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd32f339",
   "metadata": {},
   "outputs": [],
   "source": [
    "for reco_category in [\"preselection\", \"1gNp\", \"1g0p\"]:\n",
    "    if reco_category == \"preselection\":\n",
    "        sel_df = presel_merged_df\n",
    "        reco_category_latex = \"Preselection\"\n",
    "    elif reco_category in reco_categories:\n",
    "        reco_category_i = reco_categories.index(reco_category)\n",
    "        sel_df = presel_merged_df.filter(reco_category_queries[reco_category_i])\n",
    "        reco_category_latex = reco_category_labels_latex[reco_category_i]\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid selection type: {reco_category}\")\n",
    "\n",
    "    for var, bins in [\n",
    "            (\"blip_closest_upstream_distance\", np.linspace(0, 200, 21)),\n",
    "            #(\"blip_closest_upstream_angle\", np.linspace(0, 90, 19)),\n",
    "            #(\"blip_closest_upstream_impact_parameter\", np.linspace(0, 200, 21)),\n",
    "            #(\"blip_closest_upstream_energy\", np.linspace(0, 20, 21)),\n",
    "            #(\"blip_closest_upstream_dx\", np.linspace(0, 5, 11)),\n",
    "        ]:\n",
    "\n",
    "        make_plot(pred_and_data_sel_df=sel_df, bins=bins, var=var, display_var=var, title=reco_category_latex)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25443b02",
   "metadata": {},
   "source": [
    "## Nanosecond Timing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d07c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# related to https://github.com/brb-rightback/ns_demo_MCC9.10/blob/main/ns_demo_MCC9.10.ipynb\n",
    "# TODO: Validate this with data and showers, see https://microboone-docdb.fnal.gov/cgi-bin/sso/ShowDocument?docid=44781\n",
    "# Also check the manually applied shifts for all the different time periods\n",
    "\n",
    "beamon_presel_merged_df = presel_merged_df.filter(pl.col(\"filetype\") == \"data\")\n",
    "beamoff_presel_merged_df = presel_merged_df.filter(pl.col(\"filetype\") == \"ext\") \n",
    "mc_presel_merged_df = presel_merged_df.filter(~pl.col(\"filetype\").is_in([\"data\", \"ext\"]))\n",
    "\n",
    "beamoff_presel_merged_df = beamoff_presel_merged_df.with_columns(pl.col(\"wc_evtTimeNS\").alias(\"non_merge_time\"))\n",
    "beamon_presel_merged_df = beamon_presel_merged_df.with_columns((pl.col(\"wc_evtTimeNS\") + 5700).alias(\"non_merge_time\"))\n",
    "mc_presel_merged_df = mc_presel_merged_df.with_columns((pl.col(\"wc_evtTimeNS_cor\") + 1500).alias(\"non_merge_time\")) # manually shifting MC to approximately match data\n",
    "\n",
    "data_presel_merged_df = pl.concat([beamoff_presel_merged_df, beamon_presel_merged_df])\n",
    "del beamoff_presel_merged_df\n",
    "del beamon_presel_merged_df\n",
    "\n",
    "def calc_merge_time_data(run, evt_time):\n",
    "    gap = 18.936\n",
    "    if run >= 19500:\n",
    "        shift = 2920.5\n",
    "    elif run >= 17380:\n",
    "        shift = 2916.0\n",
    "    elif run >= 13697:\n",
    "        shift = 3147.3\n",
    "    elif run >= 10812:\n",
    "        shift = 3568.5\n",
    "    elif run >= 8321:\n",
    "        shift = 3610.7\n",
    "    elif run >= 5800:\n",
    "        shift = 3164.4\n",
    "    else:\n",
    "        shift = 3168.9\n",
    "        \n",
    "    tt_help = evt_time - shift + gap * 0.5\n",
    "    if np.isinf(tt_help):\n",
    "        tt_help = float('nan')\n",
    "    \n",
    "    if tt_help >= 0:\n",
    "        return (tt_help - (int(tt_help/gap) * gap)) - gap * 0.5\n",
    "    return -9999.\n",
    "\n",
    "data_presel_merged_df = data_presel_merged_df.with_columns(\n",
    "    pl.struct([\"run\", \"wc_evtTimeNS\"]).map_elements(lambda x: calc_merge_time_data(x[\"run\"], x[\"wc_evtTimeNS\"])).alias(\"merge_time\")\n",
    ")\n",
    "\n",
    "def calc_merge_time_mc(evt_time):\n",
    "    gap = 18.936\n",
    "    shift = 5.8 - 0.3\n",
    "    \n",
    "    tt_help = np.nan_to_num(evt_time - shift + gap * 0.5, nan=-9999)\n",
    "    \n",
    "    if tt_help >= 0:\n",
    "        return (tt_help - (int(tt_help/gap) * gap)) - gap * 0.5\n",
    "    return -9999.\n",
    "\n",
    "mc_presel_merged_df = mc_presel_merged_df.with_columns(\n",
    "    pl.col(\"wc_evtTimeNS_cor\").map_elements(calc_merge_time_mc).alias(\"merge_time\")\n",
    ")\n",
    "\n",
    "presel_merged_df = pl.concat([mc_presel_merged_df, data_presel_merged_df])\n",
    "del mc_presel_merged_df\n",
    "del data_presel_merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd97b24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for reco_category in [\"preselection\", \"1gNp\", \"1g0p\", \"other_outFV_dirt\", \"other_outFV_dirt_downstream\"]:\n",
    "    if reco_category == \"preselection\":\n",
    "        sel_df = presel_merged_df\n",
    "        reco_category_latex = \"Preselection\"\n",
    "    elif reco_category in reco_categories:\n",
    "        reco_category_i = reco_categories.index(reco_category)\n",
    "        sel_df = presel_merged_df.filter(reco_category_queries[reco_category_i])\n",
    "        reco_category_latex = reco_category_labels_latex[reco_category_i]\n",
    "    elif reco_category == \"other_outFV_dirt_downstream\":\n",
    "        reco_category_i = reco_categories.index(\"other_outFV_dirt\")\n",
    "        sel_df = presel_merged_df.filter(reco_category_queries[reco_category_i]).filter(pl.col(\"wc_reco_nuvtxZ\") > 500)\n",
    "        reco_category_latex = r\"Other OutFV/Dirt Downstream\"\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid selection type: {reco_category}\")\n",
    "\n",
    "    make_plot(pred_and_data_sel_df=sel_df, bins=np.linspace(8500, 11000, 21), var=\"non_merge_time\", display_var=\"Time in Spill (ns)\\n(WARNING: Fudge Factors Included)\", title=reco_category_latex)\n",
    "    make_plot(pred_and_data_sel_df=sel_df, bins=np.linspace(-9.462531250000058, 9.462531250000058, 21), var=\"merge_time\", display_var=\"Time in Bunch (ns)\", title=reco_category_latex)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f544cb",
   "metadata": {},
   "source": [
    "## Out-TPC PMT Veto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2437df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for reco_category in [\"preselection\", \"1gNp\", \"1g0p\", \"other_outFV_dirt\"]:\n",
    "\n",
    "    if reco_category == \"preselection\":\n",
    "        sel_df = presel_merged_df\n",
    "        reco_category_latex = \"Preselection\"\n",
    "    elif reco_category in reco_categories:\n",
    "        reco_category_i = reco_categories.index(reco_category)\n",
    "        sel_df = presel_merged_df.filter(reco_category_queries[reco_category_i])\n",
    "        reco_category_latex = reco_category_labels_latex[reco_category_i]\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid selection type: {reco_category}\")\n",
    "\n",
    "    make_plot(pred_and_data_sel_df=sel_df, bins=np.linspace(-1, 5, 21), var=\"(wc_flash_measPe - wc_flash_predPe) / wc_flash_predPe\", display_var=\"(meas - pred) / pred light\", title=reco_category_latex)\n",
    "    make_plot(pred_and_data_sel_df=sel_df, bins=np.linspace(-1, 10, 51), var=\"wc_WCPMTInfoChi2 / wc_WCPMTInfoNDF\", display_var=\"WC Flash chi2/ndf\\n(WARNING: Missing PMT Info for some files, set to -1)\", title=reco_category_latex, log_y=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a4daed",
   "metadata": {},
   "source": [
    "## Out-TPC CRT Veto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34838b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Look at CRT information, and if we can identify in-time out-TPC activity associated with an event\n",
    "# (even if there's no clean CRT track indicating a through-going cosmic muon)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b873d5e9",
   "metadata": {},
   "source": [
    "# Out-TPC Geometric BDT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bee08e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Look at just shower position and direction, use that to separate in-FV vs out-FV reco-1g events\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7bd31f",
   "metadata": {},
   "source": [
    "## Spacepoint SSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e1c9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: https://github.com/leehagaman/spacepoint_ssv\n",
    "# Will require processing ntuples with all cosmic spacepoints turned on\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a406ccf8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
