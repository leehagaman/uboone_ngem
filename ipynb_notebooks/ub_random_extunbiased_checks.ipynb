{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d87a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import csv\n",
    "\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d612c9d",
   "metadata": {},
   "source": [
    "# Runs 4-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436daf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "event_nums = []\n",
    "random_range_strs = []\n",
    "\n",
    "filenames.append(\"lhagaman_extunbiased_bnb_1g_overlay_run4\")\n",
    "event_nums.append(352037)\n",
    "random_range_strs.append(\"[0.848, 0.95)\")\n",
    "\n",
    "filenames.append(\"lhagaman_extunbiased_bnb_1g_overlay_run5\")\n",
    "event_nums.append(234021)\n",
    "random_range_strs.append(\"[0.848, 0.95)\")\n",
    "\n",
    "\n",
    "# from https://docs.google.com/spreadsheets/d/13a4Igf99cVNudfZXObpqNGSlDnUxlnsyo7c9x2arJWY/edit?gid=1789865876#gid=1789865876\n",
    "with open(\"../small_data_files/MicroBooNE Production campaign tracker - Run 4_5 input defs.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for items in reader:   # <-- iterate over reader, not items_by_row\n",
    "        if len(items) > 1:\n",
    "            filename = items[1]\n",
    "            event_num = items[3]\n",
    "            random_range_str = items[5]\n",
    "            if not \"prod_\" in items[1]:\n",
    "                continue\n",
    "            if not event_num:\n",
    "                continue\n",
    "            if \"none\" in random_range_str:\n",
    "                continue\n",
    "            if \"numi\" in filename or \"acpt\" in filename or \"validation\" in filename:\n",
    "                continue\n",
    "\n",
    "            if filename.endswith(\"_run4a\") or filename.endswith(\"_run4b\") or filename.endswith(\"_run4c\") or filename.endswith(\"_run4d\") or filename.endswith(\"_run5\"):\n",
    "                random_range_str = \"[0, 1]\"\n",
    "\n",
    "            random_range_str = random_range_str.replace(\"7b [\", \"[\")\n",
    "            random_range_str = random_range_str.replace(\"7d [\", \"[\")\n",
    "\n",
    "            filenames.append(filename)\n",
    "            event_nums.append(event_num)\n",
    "            random_range_strs.append(random_range_str)\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    print(str(filenames[i]).ljust(100), str(event_nums[i]).ljust(10), str(random_range_strs[i]).ljust(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94895a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_run4_ext_unbiased_events = 573419+1841799+1086278+2152781\n",
    "num_run5_ext_unbiased_events = 2317232\n",
    "\n",
    "print(\"total run 4 num ext unbiased data events: \", num_run4_ext_unbiased_events)\n",
    "\n",
    "print(\"total run 5 num ext unbiased data events: \", num_run5_ext_unbiased_events)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b146bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_filetype_range_tups = set()\n",
    "for i in range(len(filenames)):\n",
    "    if \"nc_kaon\" in filenames[i]:\n",
    "        filetype = \"nc_kaon\"\n",
    "    elif \"ncpi0\" in filenames[i]:\n",
    "        filetype = \"ncpi0\"\n",
    "    elif \"COH_pion\" in filenames[i]:\n",
    "        filetype = \"COH_pion\"\n",
    "        print(\"starting with \", filenames[i], \"changing to \", filetype)\n",
    "    elif filenames[i] in [\"prod_extunbiased_swizzle_crt_inclusive_v7_goodruns_mcc9_run4a\", \n",
    "                            \"prod_extunbiased_swizzle_crt_inclusive_v7b_goodruns_mcc9_run4b\",\n",
    "                            \"prod_extunbiased_swizzle_crt_inclusive_v7c_goodruns_mcc9_run4c\",\n",
    "                            \"prod_extunbiased_swizzle_crt_inclusive_v7d_goodruns_mcc9_run4d\",\n",
    "                            \"prod_extunbiased_swizzle_crt_inclusive_v8_goodruns_mcc9_run5\"]:\n",
    "        filetype = \"ext_unbiased_data\"\n",
    "    elif \"bnb\" in filenames[i]:\n",
    "        filetype = filenames[i].split(\"_bnb_\")[-1]\n",
    "    else:\n",
    "        print(\"not explicitly handled: \", filenames[i])\n",
    "        filetype = filenames[i]\n",
    "    range_str = random_range_strs[i]\n",
    "\n",
    "    if \"run4\" in filenames[i]:\n",
    "        run = 4\n",
    "    elif \"run5\" in filenames[i]:\n",
    "        run = 5\n",
    "    else:\n",
    "        raise ValueError(\"invalid run number: \", filenames[i])\n",
    "\n",
    "    run_filetype = f\"run{str(run)}_{filetype}\"\n",
    "    \n",
    "    unique_filetype_range_tups.add((run_filetype, range_str))\n",
    "\n",
    "for tup in unique_filetype_range_tups:\n",
    "    print(tup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f8373e",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_filenames = []\n",
    "combined_event_nums = []\n",
    "combined_random_range_strs = []\n",
    "\n",
    "for filetype_range_tup in unique_filetype_range_tups:\n",
    "    combined_filenames.append(filetype_range_tup[0])\n",
    "    combined_random_range_strs.append(filetype_range_tup[1])\n",
    "    num_events = 0\n",
    "    print(filetype_range_tup)\n",
    "    for i in range(len(filenames)):\n",
    "        if \"nc_kaon\" in filenames[i]:\n",
    "            filetype = \"nc_kaon\"\n",
    "        elif \"ncpi0\" in filenames[i]:\n",
    "            filetype = \"ncpi0\"\n",
    "        elif \"COH_pion\" in filenames[i]:\n",
    "            filetype = \"COH_pion\"\n",
    "        elif filenames[i] in [\"prod_extunbiased_swizzle_crt_inclusive_v7_goodruns_mcc9_run4a\", \n",
    "                            \"prod_extunbiased_swizzle_crt_inclusive_v7b_goodruns_mcc9_run4b\",\n",
    "                            \"prod_extunbiased_swizzle_crt_inclusive_v7c_goodruns_mcc9_run4c\",\n",
    "                            \"prod_extunbiased_swizzle_crt_inclusive_v7d_goodruns_mcc9_run4d\",\n",
    "                            \"prod_extunbiased_swizzle_crt_inclusive_v8_goodruns_mcc9_run5\"]:\n",
    "            filetype = \"ext_unbiased_data\"\n",
    "        elif \"bnb\" in filenames[i]:\n",
    "            filetype = filenames[i].split(\"_bnb_\")[-1]\n",
    "        else:\n",
    "            print(\"not explicitly handled: \", filenames[i])\n",
    "            filetype = filenames[i]\n",
    "\n",
    "        if \"run4\" in filenames[i]:\n",
    "            run = 4\n",
    "        elif \"run5\" in filenames[i]:\n",
    "            run = 5\n",
    "        else:\n",
    "            raise ValueError(\"invalid run number: \", filenames[i])\n",
    "\n",
    "        run_filetype = f\"run{str(run)}_{filetype}\"\n",
    "\n",
    "        if run_filetype == filetype_range_tup[0] and random_range_strs[i] == filetype_range_tup[1]:\n",
    "            print(\"        adding \", event_nums[i])\n",
    "            num_events += int(event_nums[i])\n",
    "            continue\n",
    "\n",
    "    combined_event_nums.append(num_events)\n",
    "\n",
    "print(f\"{combined_filenames=}\")\n",
    "print(f\"{combined_event_nums=}\")\n",
    "print(f\"{combined_random_range_strs=}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c088893d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(combined_filenames)):\n",
    "    print(combined_filenames[i], combined_event_nums[i], combined_random_range_strs[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0405b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = combined_filenames\n",
    "event_nums = combined_event_nums\n",
    "random_range_strs = combined_random_range_strs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30afdc61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper to extract intervals robustly ---\n",
    "def get_intervals(r):\n",
    "    # remove all spaces\n",
    "    r = r.replace(\" \", \"\")\n",
    "    # match [start,end)\n",
    "    matches = re.findall(r\"\\[([\\d.]+),([\\d.]+)\\)\", r)\n",
    "    return [(float(a), float(b)) for a,b in matches]\n",
    "\n",
    "# --- Build dataframe ---\n",
    "df = pd.DataFrame({\n",
    "    \"filename\": filenames,\n",
    "    \"events\": pd.to_numeric(event_nums, errors=\"coerce\"),\n",
    "    \"range\": random_range_strs\n",
    "}).dropna()\n",
    "\n",
    "# Use filename as sample\n",
    "df[\"sample\"] = df[\"filename\"]\n",
    "\n",
    "# --- Collect all unique split points ---\n",
    "split_points = set()\n",
    "for r in df[\"range\"]:\n",
    "    intervals = get_intervals(r)\n",
    "    for a,b in intervals:\n",
    "        split_points.add(a)\n",
    "        split_points.add(b)\n",
    "\n",
    "split_points = sorted(split_points)\n",
    "split_points = np.array(split_points)\n",
    "\n",
    "# --- Expand each line into sub-intervals ---\n",
    "expanded = []\n",
    "for _, row in df.iterrows():\n",
    "\n",
    "    print(\"considering sample: \", row[\"sample\"])\n",
    "    print(f\"    {row['range']=}\")\n",
    "    print(f\"    {get_intervals(row['range'])=}\")\n",
    "\n",
    "    intervals = get_intervals(row[\"range\"])\n",
    "    if not intervals:\n",
    "        print(\"no intervals found for sample: \", row[\"sample\"])\n",
    "        continue\n",
    "    \n",
    "    # total width of all intervals for proportional distribution\n",
    "    total_width = sum(end - start for start, end in intervals)\n",
    "    \n",
    "    for start, end in intervals:\n",
    "        interval_width = end - start\n",
    "        events_in_interval = row[\"events\"] * (interval_width / total_width)\n",
    "        \n",
    "        for i in range(len(split_points)-1):\n",
    "            sub_start = split_points[i]\n",
    "            sub_end = split_points[i+1]\n",
    "            # check overlap\n",
    "            overlap_start = max(sub_start, start)\n",
    "            overlap_end = min(sub_end, end)\n",
    "            if overlap_end <= overlap_start:\n",
    "                continue\n",
    "            overlap_width = overlap_end - overlap_start\n",
    "            events_in_subinterval = events_in_interval * (overlap_width / interval_width)\n",
    "            expanded.append({\n",
    "                \"sample\": row[\"sample\"],\n",
    "                \"start\": overlap_start,\n",
    "                \"end\": overlap_end,\n",
    "                \"events\": events_in_subinterval\n",
    "            })\n",
    "\n",
    "df2 = pd.DataFrame(expanded)\n",
    "\n",
    "samples = df2[\"sample\"].unique()\n",
    "\n",
    "samples = sorted(samples, key=lambda x: df2[df2[\"sample\"]==x][\"events\"].sum(), reverse=True)\n",
    "\n",
    "colors = plt.cm.tab20.colors\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "bottoms = np.zeros(len(split_points)-1)\n",
    "already_labeled_sample_names = []\n",
    "for i, sample in enumerate(samples):\n",
    "    sample_intervals = df2[df2[\"sample\"]==sample]\n",
    "    for _, row in sample_intervals.iterrows():\n",
    "        idx = np.where(split_points[:-1] == row[\"start\"])[0][0]\n",
    "        event_per_width = row[\"events\"] / (row[\"end\"] - row[\"start\"])\n",
    "        ax.fill_between(\n",
    "            [row[\"start\"], row[\"end\"]],\n",
    "            bottoms[idx:idx+1],\n",
    "            bottoms[idx:idx+1] + event_per_width,\n",
    "            step=\"post\",\n",
    "            color=colors[i % len(colors)],\n",
    "            label=sample if sample not in already_labeled_sample_names else None\n",
    "        )\n",
    "        bottoms[idx:idx+1] += event_per_width\n",
    "        already_labeled_sample_names.append(sample)\n",
    "ax.axhline(y=num_run4_ext_unbiased_events + num_run5_ext_unbiased_events, color='black', linestyle='--', label=\"All available EXT unbiased events\")\n",
    "ax.set_xlim(0,1.4)\n",
    "ax.set_ylim(0, 1.5e7)\n",
    "ax.set_xlabel(\"ubrandom\")\n",
    "ax.set_ylabel(\"Events per ubrandom width\")\n",
    "ax.set_title(\"Runs 4-5 Stacked events across ubrandom ∈ [0,1]\")\n",
    "ax.legend(loc=\"upper right\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4184be02",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "bottoms = np.zeros(len(split_points)-1)\n",
    "already_labeled_sample_names = []\n",
    "for i, sample in enumerate(samples):\n",
    "    if \"run5\" in sample:\n",
    "        continue\n",
    "    sample_intervals = df2[df2[\"sample\"]==sample]\n",
    "    for _, row in sample_intervals.iterrows():\n",
    "        idx = np.where(split_points[:-1] == row[\"start\"])[0][0]\n",
    "        event_per_width = row[\"events\"] / (row[\"end\"] - row[\"start\"])\n",
    "        ax.fill_between(\n",
    "            [row[\"start\"], row[\"end\"]],\n",
    "            bottoms[idx:idx+1],\n",
    "            bottoms[idx:idx+1] + event_per_width,\n",
    "            step=\"post\",\n",
    "            color=colors[i % len(colors)],\n",
    "            label=sample if sample not in already_labeled_sample_names else None\n",
    "        )\n",
    "        bottoms[idx:idx+1] += event_per_width\n",
    "        already_labeled_sample_names.append(sample)\n",
    "ax.axhline(y=num_run4_ext_unbiased_events, color='black', linestyle='--', label=\"All available EXT unbiased events\")\n",
    "ax.set_xlim(0,1.4)\n",
    "ax.set_ylim(0, 1.5e7)\n",
    "ax.set_xlabel(\"ubrandom\")\n",
    "ax.set_ylabel(\"Events per ubrandom width\")\n",
    "ax.set_title(\"Run 4 Stacked events across ubrandom ∈ [0,1]\")\n",
    "ax.legend(loc=\"upper right\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "bottoms = np.zeros(len(split_points)-1)\n",
    "already_labeled_sample_names = []\n",
    "for i, sample in enumerate(samples):\n",
    "    if \"run4\" in sample:\n",
    "        continue\n",
    "    sample_intervals = df2[df2[\"sample\"]==sample]\n",
    "    for _, row in sample_intervals.iterrows():\n",
    "        idx = np.where(split_points[:-1] == row[\"start\"])[0][0]\n",
    "        event_per_width = row[\"events\"] / (row[\"end\"] - row[\"start\"])\n",
    "        ax.fill_between(\n",
    "            [row[\"start\"], row[\"end\"]],\n",
    "            bottoms[idx:idx+1],\n",
    "            bottoms[idx:idx+1] + event_per_width,\n",
    "            step=\"post\",\n",
    "            color=colors[i % len(colors)],\n",
    "            label=sample if sample not in already_labeled_sample_names else None\n",
    "        )\n",
    "        bottoms[idx:idx+1] += event_per_width\n",
    "        already_labeled_sample_names.append(sample)\n",
    "ax.axhline(y=num_run5_ext_unbiased_events, color='black', linestyle='--', label=\"All available EXT unbiased events\")\n",
    "ax.set_xlim(0,1.4)\n",
    "ax.set_ylim(0, 1.5e7)\n",
    "ax.set_xlabel(\"ubrandom\")\n",
    "ax.set_ylabel(\"Events per ubrandom width\")\n",
    "ax.set_title(\"Run 5 Stacked events across ubrandom ∈ [0,1]\")\n",
    "ax.legend(loc=\"upper right\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2696a7",
   "metadata": {},
   "source": [
    "# Runs 1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89eb688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://microboone-exp.fnal.gov/at_work/AnalysisTools/data/ub_datasets_overlay.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6821f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = []\n",
    "event_nums = []\n",
    "random_range_strs = []\n",
    "\n",
    "in_bnb_section = False\n",
    "\n",
    "# from https://docs.google.com/spreadsheets/d/13a4Igf99cVNudfZXObpqNGSlDnUxlnsyo7c9x2arJWY/edit?gid=1463620863#gid=1463620863\n",
    "with open(\"../small_data_files/MicroBooNE Production campaign tracker - Run 1_2_3 input defs.csv\", \"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for items in reader:   # <-- iterate over reader, not items_by_row\n",
    "        if \"BNB Run 1\" in str(items):\n",
    "            in_bnb_section = True\n",
    "        if \"NuMI FHC Run 1\" in str(items):\n",
    "            in_bnb_section = False\n",
    "\n",
    "        if not in_bnb_section:\n",
    "            continue\n",
    "            \n",
    "        if len(items) > 1:\n",
    "            filename = items[1]\n",
    "            event_num = items[3]\n",
    "            random_range_str = items[5]\n",
    "            if not \"prod_\" in items[1]:\n",
    "                continue\n",
    "            if not event_num:\n",
    "                continue\n",
    "            if \"none\" in random_range_str:\n",
    "                continue\n",
    "            if \"numi\" in filename or filename in [\"prod_extunbiased_swizzle_inclusive_v3_goodruns_mcc9_run1_high_lifetime_750k\", \"prod_extunbiased_swizzle_inclusive_v3_goodruns_mcc9_run1_high_lifetime_100k\"]:\n",
    "                continue\n",
    "            if not \",\" in random_range_str:\n",
    "                continue\n",
    "\n",
    "\n",
    "            filenames.append(filename)\n",
    "            event_nums.append(event_num)\n",
    "            random_range_strs.append(random_range_str)\n",
    "\n",
    "for i in range(len(filenames)):\n",
    "    print(str(filenames[i]).ljust(100), str(event_nums[i]).ljust(10), str(random_range_strs[i]).ljust(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a22aaf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_run1_ext_unbiased_events = 2123950\n",
    "num_run2_ext_unbiased_events = 3091509\n",
    "num_run3_ext_unbiased_events = 4289834\n",
    "\n",
    "print(\"total run 1 num ext unbiased data events: \", num_run1_ext_unbiased_events)\n",
    "print(\"total run 2 num ext unbiased data events: \", num_run2_ext_unbiased_events)\n",
    "print(\"total run 3 num ext unbiased data events: \", num_run3_ext_unbiased_events)\n",
    "\n",
    "print((0.95 - 0.918) * num_run1_ext_unbiased_events)\n",
    "print((0.95 - 0.918) * num_run2_ext_unbiased_events)\n",
    "print((0.95 - 0.918) * num_run3_ext_unbiased_events)\n",
    "\n",
    "print((0.95 - 0.918) * (num_run1_ext_unbiased_events + num_run2_ext_unbiased_events + num_run3_ext_unbiased_events))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c044255d",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_filetype_range_tups = set()\n",
    "for i in range(len(filenames)):\n",
    "    if \"bnb_nu\" in filenames[i]:\n",
    "        filetype = \"bnb_nu\"\n",
    "    elif \"intrinsic_nue\" in filenames[i]:\n",
    "        filetype = \"intrinsic_nue\"\n",
    "    elif \"nc_delta\" in filenames[i] or \"ncdelta\" in filenames[i]:\n",
    "        filetype = \"nc_delta\"\n",
    "    elif \"nc_pi0\" in filenames[i] or \"ncpi0\" in filenames[i]:\n",
    "        filetype = \"nc_pi0\"\n",
    "    elif \"dirt\" in filenames[i]:\n",
    "        filetype = \"dirt\"\n",
    "    elif \"eLee_high\" in filenames[i]:\n",
    "        filetype = \"eLee_high\"\n",
    "    elif \"eLee_low\" in filenames[i]:\n",
    "        filetype = \"eLee_low\"\n",
    "    elif \"full_osc\" in filenames[i]:\n",
    "        filetype = \"full_osc\"\n",
    "    elif \"bnb_nu_lowE\" in filenames[i] or \"overlay_lowE\" in filenames[i]:\n",
    "        filetype = \"bnb_nu_lowE\"\n",
    "    elif \"nc_pi02\" in filenames[i]:\n",
    "        filetype = \"nc_pi02\"\n",
    "    elif \"nc_kaon\" in filenames[i]:\n",
    "        filetype = \"nc_kaon\"\n",
    "    elif \"coherent_pion\" in filenames[i]:\n",
    "        filetype = \"coherent_pion\"\n",
    "    elif \"DL_vertexing\" in filenames[i]:\n",
    "        filetype = \"DL_vertexing \"\n",
    "    else:\n",
    "        print(\"not explicitly handled: \", filenames[i])\n",
    "        filetype = filenames[i]\n",
    "    range_str = random_range_strs[i]\n",
    "\n",
    "    if \"run1\" in filenames[i]:\n",
    "        run = 1\n",
    "    elif \"run2\" in filenames[i]:\n",
    "        run = 2\n",
    "    elif \"run3\" in filenames[i]:\n",
    "        run = 3\n",
    "    else:\n",
    "        raise ValueError(\"invalid run number: \", filenames[i])\n",
    "\n",
    "    run_filetype = f\"run{str(run)}_{filetype}\"\n",
    "    \n",
    "    unique_filetype_range_tups.add((run_filetype, range_str))\n",
    "\n",
    "for tup in unique_filetype_range_tups:\n",
    "    print(tup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b995bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Helper to extract intervals robustly ---\n",
    "def get_intervals(r):\n",
    "    # remove all spaces\n",
    "    r = r.replace(\" \", \"\")\n",
    "    # match [start,end)\n",
    "    matches = re.findall(r\"\\[([\\d.]+),([\\d.]+)\\)\", r)\n",
    "    return [(float(a), float(b)) for a,b in matches]\n",
    "\n",
    "# --- Build dataframe ---\n",
    "df = pd.DataFrame({\n",
    "    \"filename\": filenames,\n",
    "    \"events\": pd.to_numeric(event_nums, errors=\"coerce\"),\n",
    "    \"range\": random_range_strs\n",
    "}).dropna()\n",
    "\n",
    "# Use filename as sample\n",
    "df[\"sample\"] = df[\"filename\"]\n",
    "\n",
    "# --- Collect all unique split points ---\n",
    "split_points = set()\n",
    "for r in df[\"range\"]:\n",
    "    intervals = get_intervals(r)\n",
    "    for a,b in intervals:\n",
    "        split_points.add(a)\n",
    "        split_points.add(b)\n",
    "\n",
    "split_points = sorted(split_points)\n",
    "split_points = np.array(split_points)\n",
    "\n",
    "# --- Expand each line into sub-intervals ---\n",
    "expanded = []\n",
    "for _, row in df.iterrows():\n",
    "\n",
    "    print(\"considering sample: \", row[\"sample\"])\n",
    "    print(f\"    {row['range']=}\")\n",
    "    print(f\"    {get_intervals(row['range'])=}\")\n",
    "\n",
    "    intervals = get_intervals(row[\"range\"])\n",
    "    if not intervals:\n",
    "        print(\"no intervals found for sample: \", row[\"sample\"])\n",
    "        continue\n",
    "    \n",
    "    # total width of all intervals for proportional distribution\n",
    "    total_width = sum(end - start for start, end in intervals)\n",
    "    \n",
    "    for start, end in intervals:\n",
    "        interval_width = end - start\n",
    "        events_in_interval = row[\"events\"] * (interval_width / total_width)\n",
    "        \n",
    "        for i in range(len(split_points)-1):\n",
    "            sub_start = split_points[i]\n",
    "            sub_end = split_points[i+1]\n",
    "            # check overlap\n",
    "            overlap_start = max(sub_start, start)\n",
    "            overlap_end = min(sub_end, end)\n",
    "            if overlap_end <= overlap_start:\n",
    "                continue\n",
    "            overlap_width = overlap_end - overlap_start\n",
    "            events_in_subinterval = events_in_interval * (overlap_width / interval_width)\n",
    "            expanded.append({\n",
    "                \"sample\": row[\"sample\"],\n",
    "                \"start\": overlap_start,\n",
    "                \"end\": overlap_end,\n",
    "                \"events\": events_in_subinterval\n",
    "            })\n",
    "\n",
    "df2 = pd.DataFrame(expanded)\n",
    "\n",
    "samples = df2[\"sample\"].unique()\n",
    "\n",
    "samples = sorted(samples, key=lambda x: df2[df2[\"sample\"]==x][\"events\"].sum(), reverse=True)\n",
    "\n",
    "colors = plt.cm.tab20.colors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4cdf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "bottoms = np.zeros(len(split_points)-1)\n",
    "already_labeled_sample_names = []\n",
    "for i, sample in enumerate(samples):\n",
    "    if \"run2\" in sample or \"run3\" in sample:\n",
    "        continue\n",
    "    sample_intervals = df2[df2[\"sample\"]==sample]\n",
    "    for _, row in sample_intervals.iterrows():\n",
    "        idx = np.where(split_points[:-1] == row[\"start\"])[0][0]\n",
    "        event_per_width = row[\"events\"] / (row[\"end\"] - row[\"start\"])\n",
    "        ax.fill_between(\n",
    "            [row[\"start\"], row[\"end\"]],\n",
    "            bottoms[idx:idx+1],\n",
    "            bottoms[idx:idx+1] + event_per_width,\n",
    "            step=\"post\",\n",
    "            color=colors[i % len(colors)],\n",
    "            label=sample if sample not in already_labeled_sample_names else None\n",
    "        )\n",
    "        bottoms[idx:idx+1] += event_per_width\n",
    "        already_labeled_sample_names.append(sample)\n",
    "ax.axhline(y=num_run1_ext_unbiased_events, color='black', linestyle='--', label=\"Run 1 total available EXT unbiased events\")\n",
    "ax.set_xlim(0,1.4)\n",
    "ax.set_ylim(0, 1.5e7)\n",
    "ax.set_xlabel(\"ubrandom\")\n",
    "ax.set_ylabel(\"Events per ubrandom width\")\n",
    "ax.set_title(\"Run 1 Stacked events across ubrandom ∈ [0,1]\")\n",
    "ax.legend(loc=\"upper right\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "bottoms = np.zeros(len(split_points)-1)\n",
    "already_labeled_sample_names = []\n",
    "for i, sample in enumerate(samples):\n",
    "    if \"run1\" in sample or \"run3\" in sample:\n",
    "        continue\n",
    "    sample_intervals = df2[df2[\"sample\"]==sample]\n",
    "    for _, row in sample_intervals.iterrows():\n",
    "        idx = np.where(split_points[:-1] == row[\"start\"])[0][0]\n",
    "        event_per_width = row[\"events\"] / (row[\"end\"] - row[\"start\"])\n",
    "        ax.fill_between(\n",
    "            [row[\"start\"], row[\"end\"]],\n",
    "            bottoms[idx:idx+1],\n",
    "            bottoms[idx:idx+1] + event_per_width,\n",
    "            step=\"post\",\n",
    "            color=colors[i % len(colors)],\n",
    "            label=sample if sample not in already_labeled_sample_names else None\n",
    "        )\n",
    "        bottoms[idx:idx+1] += event_per_width\n",
    "        already_labeled_sample_names.append(sample)\n",
    "ax.axhline(y=num_run2_ext_unbiased_events, color='black', linestyle='--', label=\"Run 1 total available EXT unbiased events\")\n",
    "ax.set_xlim(0,1.4)\n",
    "ax.set_ylim(0, 1.5e7)\n",
    "ax.set_xlabel(\"ubrandom\")\n",
    "ax.set_ylabel(\"Events per ubrandom width\")\n",
    "ax.set_title(\"Run 2 Stacked events across ubrandom ∈ [0,1]\")\n",
    "ax.legend(loc=\"upper right\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,7))\n",
    "bottoms = np.zeros(len(split_points)-1)\n",
    "already_labeled_sample_names = []\n",
    "for i, sample in enumerate(samples):\n",
    "    if \"run1\" in sample or \"run2\" in sample:\n",
    "        continue\n",
    "    sample_intervals = df2[df2[\"sample\"]==sample]\n",
    "    for _, row in sample_intervals.iterrows():\n",
    "        idx = np.where(split_points[:-1] == row[\"start\"])[0][0]\n",
    "        event_per_width = row[\"events\"] / (row[\"end\"] - row[\"start\"])\n",
    "        ax.fill_between(\n",
    "            [row[\"start\"], row[\"end\"]],\n",
    "            bottoms[idx:idx+1],\n",
    "            bottoms[idx:idx+1] + event_per_width,\n",
    "            step=\"post\",\n",
    "            color=colors[i % len(colors)],\n",
    "            label=sample if sample not in already_labeled_sample_names else None\n",
    "        )\n",
    "        bottoms[idx:idx+1] += event_per_width\n",
    "        already_labeled_sample_names.append(sample)\n",
    "ax.axhline(y=num_run3_ext_unbiased_events, color='black', linestyle='--', label=\"Run 1 total available EXT unbiased events\")\n",
    "ax.set_xlim(0,1.4)\n",
    "ax.set_ylim(0, 1.5e7)\n",
    "ax.set_xlabel(\"ubrandom\")\n",
    "ax.set_ylabel(\"Events per ubrandom width\")\n",
    "ax.set_title(\"Run 3 Stacked events across ubrandom ∈ [0,1]\")\n",
    "ax.legend(loc=\"upper right\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c11b3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7518d3a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
