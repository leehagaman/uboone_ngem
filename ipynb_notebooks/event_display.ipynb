{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import polars as pl\n",
    "import pickle\n",
    "import uproot\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from src.file_locations import intermediate_files_location, data_files_location\n",
    "from src.plotting_3d import plot_event\n",
    "from src.signal_categories import train_category_labels, train_category_labels_latex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = \"all_vars\"\n",
    "\n",
    "reco_categories = train_category_labels\n",
    "reco_category_labels_latex = train_category_labels_latex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"loading all_df.parquet...\")\n",
    "all_df = pl.read_parquet(f\"{intermediate_files_location}/all_df.parquet\")\n",
    "print(f\"{all_df.shape=}\")\n",
    "\n",
    "# this only includes predictions for events passing the preselection used during training\n",
    "print(\"loading predictions.parquet...\")\n",
    "pred_df = pl.read_parquet(f\"../training_outputs/{training}/predictions.parquet\")\n",
    "print(f\"{pred_df.shape=}\")\n",
    "\n",
    "print(\"merging all_df and predictions.pkl...\")\n",
    "merged_df_no_data_drop = all_df.join(\n",
    "    pred_df, \n",
    "    on=[\"filetype\", \"run\", \"subrun\", \"event\"], \n",
    "    how=\"left\"\n",
    ")\n",
    "del all_df\n",
    "del pred_df\n",
    "\n",
    "# Use polars expressions to set \"used_for_training\" and \"used_for_testing\" for wc_kine_reco_Enu < 0\n",
    "merged_df_no_data_drop = merged_df_no_data_drop.with_columns([\n",
    "    pl.when(pl.col(\"wc_kine_reco_Enu\") < 0)\n",
    "      .then(False)\n",
    "      .otherwise(pl.col(\"used_for_training\"))\n",
    "      .alias(\"used_for_training\"),\n",
    "    pl.when(pl.col(\"wc_kine_reco_Enu\") < 0)\n",
    "      .then(True)\n",
    "      .otherwise(pl.col(\"used_for_testing\"))\n",
    "      .alias(\"used_for_testing\")\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pred = merged_df_no_data_drop.filter(\n",
    "    ~pl.col(\"filetype\").is_in([\"data\", \"isotropic_one_gamma_overlay\", \"delete_one_gamma_overlay\"])\n",
    ")\n",
    "full_data = merged_df_no_data_drop.filter(pl.col(\"filetype\") == \"data\")\n",
    "\n",
    "prob_categories = [\"prob_\" + cat for cat in reco_categories]\n",
    "for prob in prob_categories:\n",
    "    full_pred = full_pred.with_columns(pl.col(prob).fill_null(-1))\n",
    "    full_data = full_data.with_columns(pl.col(prob).fill_null(-1))\n",
    "\n",
    "generic_pred_df = full_pred.filter(pl.col(\"wc_kine_reco_Enu\") > 0)\n",
    "non_generic_pred_df = full_pred.filter(pl.col(\"wc_kine_reco_Enu\") < 0)\n",
    "del full_pred\n",
    "\n",
    "num_train_events = generic_pred_df.filter(pl.col(\"used_for_training\") == True).height\n",
    "num_test_events = generic_pred_df.filter(pl.col(\"used_for_testing\") == True).height\n",
    "print(f\"num_train_events: {num_train_events}, num_test_events: {num_test_events}\")\n",
    "frac_test = num_test_events / (num_train_events + num_test_events)\n",
    "print(f\"weighting up preselected prediction events by the fraction of test/train events: {frac_test:.3f}\")\n",
    "\n",
    "# Modify weights using polars expressions\n",
    "generic_pred_df = generic_pred_df.with_columns(\n",
    "    pl.when(pl.col(\"used_for_testing\"))\n",
    "    .then(pl.col(\"wc_net_weight\") / frac_test)\n",
    "    .otherwise(pl.col(\"wc_net_weight\"))\n",
    "    .alias(\"wc_net_weight\")\n",
    ")\n",
    "\n",
    "full_pred = pl.concat([generic_pred_df, non_generic_pred_df])\n",
    "del generic_pred_df\n",
    "del non_generic_pred_df\n",
    "\n",
    "test_pred = full_pred.filter(pl.col(\"used_for_testing\") == True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = test_pred.with_columns(\n",
    "    pl.concat_list(prob_categories).list.arg_max().alias(\"reco_category_argmax_index\")\n",
    ")\n",
    "\n",
    "full_data = full_data.with_columns(\n",
    "    pl.concat_list(prob_categories).list.arg_max().alias(\"reco_category_argmax_index\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del test_pred # not using this for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{intermediate_files_location}/reco_category_queries.pkl\", \"rb\") as f:\n",
    "    reco_category_queries = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_plots_per_cat = 10\n",
    "\n",
    "all_reco_cat_data_dfs = []\n",
    "for reco_i in range(len(reco_categories)):\n",
    "    curr_reco_cat_data_df = full_data.filter(reco_category_queries[reco_i])\n",
    "\n",
    "    num_plots = min(num_plots_per_cat, curr_reco_cat_data_df.height)\n",
    "\n",
    "    curr_reco_cat_data_df = curr_reco_cat_data_df.head(num_plots)\n",
    "\n",
    "    curr_reco_cat_data_df = curr_reco_cat_data_df.with_columns(\n",
    "        pl.lit(reco_categories[reco_i]).alias(\"reco_category\")\n",
    "    )\n",
    "\n",
    "    curr_reco_cat_data_df = curr_reco_cat_data_df.select([\n",
    "        \"filename\", \"filetype\", \"run\", \"subrun\", \"event\", \"reco_category\",\n",
    "    ])\n",
    "\n",
    "    all_reco_cat_data_dfs.append(curr_reco_cat_data_df)\n",
    "\n",
    "all_reco_cat_data_df = pl.concat(all_reco_cat_data_dfs)\n",
    "\n",
    "all_reco_cat_data_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacepoint_vars = [\n",
    "    \"Trecchargeblob_spacepoints_x\",\n",
    "    \"Trecchargeblob_spacepoints_y\",\n",
    "    \"Trecchargeblob_spacepoints_z\",\n",
    "    \"Trecchargeblob_spacepoints_q\",\n",
    "]\n",
    "\n",
    "with uproot.open(f\"{data_files_location}/MCC9.10_Run4b_v10_04_07_11_BNB_beam_on_surprise_reco2_hist.root\") as f:\n",
    "    dic = {}\n",
    "    dic.update(f[\"wcpselection\"][\"T_spacepoints\"].arrays(spacepoint_vars, library=\"np\"))\n",
    "    dic.update(f[\"wcpselection\"][\"T_eval\"].arrays([\"run\", \"subrun\", \"event\"], library=\"np\"))\n",
    "\n",
    "# Convert numpy arrays to lists so Polars recognizes them as List types\n",
    "list_dic = {}\n",
    "for var in dic.keys():\n",
    "    list_dic[var] = [arr.tolist() if isinstance(arr, np.ndarray) else arr for arr in dic[var]]\n",
    "\n",
    "spacepoints_df = pl.DataFrame(list_dic)\n",
    "\n",
    "spacepoints_df = spacepoints_df.with_columns(pl.lit(\"MCC9.10_Run4b_v10_04_07_11_BNB_beam_on_surprise_reco2_hist.root\").alias(\"filename\"))\n",
    "\n",
    "# filter out events with no spacepoints\n",
    "spacepoints_df = spacepoints_df.filter(pl.col(spacepoint_vars[0]).list.len() > 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = all_reco_cat_data_df.join(spacepoints_df, on=[\"filename\", \"run\", \"subrun\", \"event\"], how=\"left\")\n",
    "\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_cat = \"\"\n",
    "for i in range(merged_df.height):\n",
    "    run = merged_df[\"run\"][i]\n",
    "    subrun = merged_df[\"subrun\"][i]\n",
    "    event = merged_df[\"event\"][i]\n",
    "    reco_category = merged_df[\"reco_category\"][i]\n",
    "\n",
    "    if reco_category != prev_cat:\n",
    "        print(f\"######################### {reco_category} #########################\")\n",
    "        prev_cat = reco_category\n",
    "\n",
    "    plt.figure(figsize=(7, 5))\n",
    "    plt.scatter(merged_df[\"Trecchargeblob_spacepoints_z\"][i], merged_df[\"Trecchargeblob_spacepoints_x\"][i], c=merged_df[\"Trecchargeblob_spacepoints_q\"][i], \n",
    "            cmap=\"jet\", s=2, vmin=0, vmax=10_000)\n",
    "    #plt.colorbar()\n",
    "    plt.xlabel(\"z\")\n",
    "    plt.ylabel(\"x\")\n",
    "    plt.title(f\"{reco_category} Candidate From Open Data\\nRSE {run} {subrun} {event}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1/0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# event with a proton blip upstream of one shower\n",
    "event_index = 7\n",
    "\n",
    "# each entry is name : (points, color, cmap, size, visible)\n",
    "points_dic = {}\n",
    "\n",
    "points_dic[\"WC_reco_nu_vtx\"] = (\n",
    "    np.array([all_df[\"wc_reco_nuvtxX\"].to_numpy()[event_index], all_df[\"wc_reco_nuvtxY\"].to_numpy()[event_index], all_df[\"wc_reco_nuvtxZ\"].to_numpy()[event_index]]),\n",
    "    \"green\",\n",
    "    None,\n",
    "    10,\n",
    "    \"legendonly\"\n",
    ")\n",
    "points_dic[\"true_nu_vtx\"] = (\n",
    "    np.array([all_df[\"wc_truth_vtxX\"].to_numpy()[event_index], all_df[\"wc_truth_vtxY\"].to_numpy()[event_index], all_df[\"wc_truth_vtxZ\"].to_numpy()[event_index]]),\n",
    "    \"red\",\n",
    "    None,\n",
    "    10,\n",
    "    \"legendonly\"\n",
    ")\n",
    "points_dic[\"true_corr_nu_vtx\"] = (\n",
    "    np.array([all_df[\"wc_truth_corr_nuvtxX\"].to_numpy()[event_index], all_df[\"wc_truth_corr_nuvtxY\"].to_numpy()[event_index], all_df[\"wc_truth_corr_nuvtxZ\"].to_numpy()[event_index]]),\n",
    "    \"yellow\",\n",
    "    None,\n",
    "    10,\n",
    "    \"legendonly\"\n",
    ")\n",
    "points_dic[\"Trec_spacepoints\"] = (\n",
    "    np.vstack((all_df[\"wc_Trec_spacepoints_x\"].to_numpy()[event_index], all_df[\"wc_Trec_spacepoints_y\"].to_numpy()[event_index], all_df[\"wc_Trec_spacepoints_z\"].to_numpy()[event_index])).T,\n",
    "    \"red\",\n",
    "    None,\n",
    "    1,\n",
    "    \"legendonly\"\n",
    ")\n",
    "points_dic[\"Treccharge_spacepoints\"] = (\n",
    "    np.vstack((all_df[\"wc_Treccharge_spacepoints_x\"].to_numpy()[event_index], all_df[\"wc_Treccharge_spacepoints_y\"].to_numpy()[event_index], all_df[\"wc_Treccharge_spacepoints_z\"].to_numpy()[event_index])).T,\n",
    "    \"blue\",\n",
    "    None,\n",
    "    1,\n",
    "    \"legendonly\"\n",
    ")\n",
    "points_dic[\"Trecchargeblob_spacepoints\"] = (\n",
    "    np.vstack((all_df[\"wc_Trecchargeblob_spacepoints_x\"].to_numpy()[event_index], all_df[\"wc_Trecchargeblob_spacepoints_y\"].to_numpy()[event_index], all_df[\"wc_Trecchargeblob_spacepoints_z\"].to_numpy()[event_index])).T,\n",
    "    all_df[\"wc_Trecchargeblob_spacepoints_q\"].to_numpy()[event_index],\n",
    "    \"jet\",\n",
    "    1,\n",
    "    True\n",
    ")\n",
    "\n",
    "points_dic[\"electron blips\"] = (\n",
    "    np.vstack((all_df[\"electron_blip_x\"].to_numpy()[event_index], all_df[\"electron_blip_y\"].to_numpy()[event_index], all_df[\"electron_blip_z\"].to_numpy()[event_index])).T,\n",
    "    \"orange\",\n",
    "    None,\n",
    "    5,\n",
    "    True\n",
    ")\n",
    "points_dic[\"proton blips\"] = (\n",
    "    np.vstack((all_df[\"proton_blip_x\"].to_numpy()[event_index], all_df[\"proton_blip_y\"].to_numpy()[event_index], all_df[\"proton_blip_z\"].to_numpy()[event_index])).T,\n",
    "    \"blue\",\n",
    "    None,\n",
    "    5,\n",
    "    True\n",
    ")\n",
    "points_dic[\"other blips\"] = (\n",
    "    np.vstack((all_df[\"other_blip_x\"].to_numpy()[event_index], all_df[\"other_blip_y\"].to_numpy()[event_index], all_df[\"other_blip_z\"].to_numpy()[event_index])).T,\n",
    "    \"purple\",\n",
    "    None,\n",
    "    5,\n",
    "    True\n",
    ")\n",
    "\n",
    "plot_event(event_index, points_dic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uv_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
